{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14649cef",
   "metadata": {},
   "source": [
    "### Load in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a73ebe7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T23:48:05.055371Z",
     "start_time": "2025-04-19T23:47:57.691466Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Use read_excel and use participant_id as the index\n",
    "train_cat = pd.read_excel(\n",
    "    \"../../widsdatathon2025/TRAIN_NEW/TRAIN_CATEGORICAL_METADATA_new.xlsx\")\n",
    "train_func = pd.read_csv(\"../../widsdatathon2025/TRAIN_NEW/\"\n",
    "                         \"TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv\")\n",
    "train_quant = pd.read_excel(\n",
    "    \"../../widsdatathon2025/TRAIN_NEW/TRAIN_QUANTITATIVE_METADATA_new.xlsx\")\n",
    "train_soln = pd.read_excel(\n",
    "    \"../../widsdatathon2025/TRAIN_NEW/TRAINING_SOLUTIONS.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5a6a6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:42:19.208593Z",
     "start_time": "2025-04-19T22:42:19.188548Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set index for merging\n",
    "train_cat.set_index(\"participant_id\", inplace=True)\n",
    "train_quant.set_index(\"participant_id\", inplace=True)\n",
    "train_func.set_index(\"participant_id\", inplace=True)\n",
    "train_soln.set_index(\"participant_id\", inplace=True)\n",
    "\n",
    "# train_cat.head()\n",
    "train_func.head()\n",
    "# train_quant.head()\n",
    "# train_soln.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406df64c16f6625a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## PCA for the functional connectome matrix to reduce dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7849a1151a7af0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:42:28.435724Z",
     "start_time": "2025-04-19T22:42:19.207988Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Select only fMRI columns\n",
    "fmri_data = train_func.drop(columns=['participant_id'], errors='ignore')\n",
    "\n",
    "# Apply PCA to reduce to top N components (e.g. 50)\n",
    "pca = PCA(n_components=50)\n",
    "fmri_pca = pca.fit_transform(fmri_data)\n",
    "\n",
    "train_func_pca = pd.DataFrame(fmri_pca, index=train_func.index,\n",
    "                           columns=[f'fmri_pca_{i}' for i in range(1, 51)])\n",
    "train_func_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a5a24f4a19a842",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Interpolate missing values with mean for quant and cat dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3161a9934e682c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:42:28.494379Z",
     "start_time": "2025-04-19T22:42:28.445148Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check missing values *before* merging\n",
    "missing = train_quant.isnull().sum()\n",
    "missing_cat = train_cat.isnull().sum()\n",
    "print(\"Missing values in train_quant:\\n\", missing[missing > 0])\n",
    "print(\"Missing values in train_cat:\\n\", missing_cat[missing_cat > 0])\n",
    "\n",
    "# Define columns with small gaps to impute\n",
    "small_gap_cols = [\n",
    "    'EHQ_EHQ_Total', 'ColorVision_CV_Score',\n",
    "    'APQ_P_APQ_P_CP', 'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV',\n",
    "    'APQ_P_APQ_P_OPD', 'APQ_P_APQ_P_PM', 'APQ_P_APQ_P_PP',\n",
    "    'SDQ_SDQ_Conduct_Problems', 'SDQ_SDQ_Difficulties_Total',\n",
    "    'SDQ_SDQ_Emotional_Problems', 'SDQ_SDQ_Externalizing',\n",
    "    'SDQ_SDQ_Generating_Impact', 'SDQ_SDQ_Hyperactivity',\n",
    "    'SDQ_SDQ_Internalizing', 'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial',\n",
    "    'PreInt_Demos_Fam_Child_Ethnicity', 'PreInt_Demos_Fam_Child_Race',\n",
    "    'MRI_Track_Scan_Location'\n",
    "]\n",
    "\n",
    "small_gap_cols_cat = [\n",
    "    'Barratt_Barratt_P1_Edu', 'Barratt_Barratt_P1_Occ'\n",
    "]\n",
    "\n",
    "# Fill small gaps using column means\n",
    "for col in small_gap_cols:\n",
    "    if col in train_quant.columns:\n",
    "        train_quant[col] = train_quant[col].fillna(train_quant[col].mean())\n",
    "for col in small_gap_cols_cat:\n",
    "    if col in train_cat.columns:\n",
    "        train_cat[col] = train_cat[col].fillna(train_cat[col].mean())\n",
    "\n",
    "train_quant.drop(columns=['MRI_Track_Age_at_Scan'], inplace=True) # Dropped\n",
    "train_cat.drop(columns=['Barratt_Barratt_P2_Occ', 'Barratt_Barratt_P2_Edu'], \n",
    "              inplace=True) # Dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2138a83a91362272",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:42:28.516882Z",
     "start_time": "2025-04-19T22:42:28.459903Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check missing values *before* merging\n",
    "missing = train_quant.isnull().sum()\n",
    "print(\"Missing values in train_quant:\\n\", missing[missing > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268e809ef085e969",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:42:28.517823Z",
     "start_time": "2025-04-19T22:42:28.471209Z"
    }
   },
   "outputs": [],
   "source": [
    "train_quant.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87099bf1a77809d8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Feature Selection for train_quant using random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67d283a7b1706d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:42:28.554947Z",
     "start_time": "2025-04-19T22:42:28.479239Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make sure participant_id is a column, not the index\n",
    "train_quant = train_quant.reset_index()\n",
    "train_cat = train_cat.reset_index()\n",
    "train_soln = train_soln.reset_index()\n",
    "train_quant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d938a182655bc022",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:42:28.572496Z",
     "start_time": "2025-04-19T22:42:28.496734Z"
    }
   },
   "outputs": [],
   "source": [
    "train_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c527621fb53507",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:42:28.696230Z",
     "start_time": "2025-04-19T22:42:28.510125Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine with targets temporarily\n",
    "quant_with_targets = train_quant.merge(train_soln[['participant_id', 'ADHD_Outcome',\n",
    "                                                   'Sex_F']], on='participant_id')\n",
    "\n",
    "# Compute correlations\n",
    "corrs = quant_with_targets.drop(columns='participant_id').corr()\n",
    "\n",
    "# Grab correlation with targets\n",
    "adhd_corr = corrs['ADHD_Outcome'].abs().sort_values(ascending=False)\n",
    "sex_corr = corrs['Sex_F'].abs().sort_values(ascending=False)\n",
    "\n",
    "# Keep top N or those above a threshold\n",
    "top_adhd_feats = adhd_corr[adhd_corr > 0.05].index.tolist()\n",
    "top_sex_feats = sex_corr[sex_corr > 0.05].index.tolist()\n",
    "\n",
    "# Union of both sets, drop targets themselves if included\n",
    "quant_selected = list(set(top_adhd_feats + top_sex_feats) - {'ADHD_Outcome', 'Sex_F'})\n",
    "quant_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfff74ffa1b4e36b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:42:29.107963Z",
     "start_time": "2025-04-19T22:42:28.592837Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Merge everything on participant_id\n",
    "X_full = train_quant[['participant_id'] + quant_selected] \\\n",
    "    .merge(train_cat, on='participant_id') \\\n",
    "    .merge(train_func_pca, on='participant_id')\n",
    "\n",
    "# Target labels\n",
    "y = train_soln[['participant_id', 'ADHD_Outcome', 'Sex_F']]\n",
    "\n",
    "# Align rows across X and y\n",
    "X_full = X_full.merge(y, on='participant_id')\n",
    "y = X_full[['ADHD_Outcome', 'Sex_F']]\n",
    "X_full = X_full.drop(columns=['ADHD_Outcome', 'Sex_F'])\n",
    "\n",
    "# Use combined target just for ranking features\n",
    "combo_target = y['ADHD_Outcome'] + y['Sex_F']\n",
    "\n",
    "# Train the Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_full.drop(columns=['participant_id']), combo_target)\n",
    "\n",
    "# Rank feature importances\n",
    "feat_importances = pd.Series(rf.feature_importances_, index=X_full.drop(columns=['participant_id']).columns)\n",
    "top_features_final = feat_importances.sort_values(ascending=False).head(50).index.tolist()\n",
    "\n",
    "# Final X for model training\n",
    "X_selected = X_full[top_features_final]\n",
    "X_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3597474bf27bb8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:42:29.803749Z",
     "start_time": "2025-04-19T22:42:29.118950Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_selected)\n",
    "\n",
    "# Convert to tensors\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y[['ADHD_Outcome', 'Sex_F']].values, dtype=torch.float32)\n",
    "\n",
    "# Stratified train/test split\n",
    "stratify_labels = y['ADHD_Outcome'].astype(str) + y['Sex_F'].astype(str)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tensor, y_tensor, test_size=0.2, random_state=42, stratify=stratify_labels)\n",
    "\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "test_ds = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=32)\n",
    "\n",
    "# Beefed-up model\n",
    "class BetterMultiOutputNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.head_adhd = nn.Linear(128, 1)\n",
    "        self.head_sex = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shared_out = self.shared(x)\n",
    "        return torch.sigmoid(self.head_adhd(shared_out)), torch.sigmoid(self.head_sex(shared_out))\n",
    "\n",
    "# Weighted BCE Loss with 2x weight for Female ADHD cases\n",
    "class WeightedBCELoss(nn.Module):\n",
    "    def __init__(self, weight_female_adhd=2):\n",
    "        super(WeightedBCELoss, self).__init__()\n",
    "        self.weight_female_adhd = weight_female_adhd\n",
    "\n",
    "    def forward(self, predictions, targets, sex):\n",
    "        # Calculate standard BCE loss\n",
    "        bce_loss = nn.BCEWithLogitsLoss(reduction='none')(predictions, targets)\n",
    "        \n",
    "        # Apply weight for female ADHD cases (ADHD_Outcome=1, Sex_F=1)\n",
    "        weight = torch.ones_like(bce_loss)\n",
    "        weight[(targets == 1) & (sex == 1)] = self.weight_female_adhd\n",
    "        \n",
    "        # Apply the weights to the loss\n",
    "        weighted_loss = weight * bce_loss\n",
    "        return weighted_loss.mean()\n",
    "\n",
    "# Initialize model and loss function\n",
    "model = BetterMultiOutputNN(X_selected.shape[1])\n",
    "weighted_criterion = WeightedBCELoss(weight_female_adhd=2)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n",
    "\n",
    "# Training loop with early stopping\n",
    "best_val_loss = np.inf\n",
    "patience = 5\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for xb, yb in train_loader:\n",
    "        adhd_pred, sex_pred = model(xb)\n",
    "        # Extract ADHD and Sex labels\n",
    "        adhd_labels = yb[:, 0]\n",
    "        sex_labels = yb[:, 1]\n",
    "        \n",
    "        # Compute weighted loss for both ADHD and Sex\n",
    "        loss_adhd = weighted_criterion(adhd_pred.squeeze(), adhd_labels, sex_labels)\n",
    "        loss_sex = weighted_criterion(sex_pred.squeeze(), sex_labels, sex_labels)\n",
    "        \n",
    "        # Total loss\n",
    "        loss = loss_adhd + loss_sex\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            adhd_pred, sex_pred = model(xb)\n",
    "            loss_adhd = weighted_criterion(adhd_pred.squeeze(), yb[:, 0], yb[:, 1])\n",
    "            loss_sex = weighted_criterion(sex_pred.squeeze(), yb[:, 1], yb[:, 1])\n",
    "            val_loss = loss_adhd + loss_sex\n",
    "            val_losses.append(val_loss.item())\n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {running_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_model = model.state_dict()\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# Evaluation\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "all_preds, all_true = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        adhd_pred, sex_pred = model(xb)\n",
    "        preds = torch.cat([adhd_pred, sex_pred], dim=1)\n",
    "        all_preds.append(preds)\n",
    "        all_true.append(yb)\n",
    "\n",
    "all_preds = torch.cat(all_preds).numpy()\n",
    "all_true = torch.cat(all_true).numpy()\n",
    "\n",
    "# Thresholding\n",
    "adhd_pred_labels = (all_preds[:, 0] > 0.5).astype(int)\n",
    "sex_pred_labels = (all_preds[:, 1] > 0.5).astype(int)\n",
    "\n",
    "# Ensure the true labels are correctly handled (indexing properly)\n",
    "all_true_adhd = all_true[:, 0].astype(int)\n",
    "all_true_sex = all_true[:, 1].astype(int)\n",
    "\n",
    "# Compute weighted F1 Score with 2x weight for Female ADHD cases\n",
    "def weighted_f1(y_true, y_pred, weight_column):\n",
    "    # Assign a weight of 2x for Female ADHD cases\n",
    "    weight = np.ones_like(y_true)\n",
    "    weight[(y_true == 1) & (weight_column == 1)] = 3  # Apply 2x weight for Female ADHD\n",
    "    \n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', sample_weight=weight)\n",
    "    return f1\n",
    "\n",
    "f1_adhd = weighted_f1(all_true_adhd, adhd_pred_labels, all_true_sex)\n",
    "f1_sex = weighted_f1(all_true_sex, sex_pred_labels, all_true_sex)\n",
    "\n",
    "print(f\"\\nADHD Weighted F1 Score: {f1_adhd:.4f}\")\n",
    "print(f\"Sex Weighted F1 Score: {f1_sex:.4f}\")\n",
    "\n",
    "# Metrics for ADHD\n",
    "def print_metrics(y_true, y_pred, name):\n",
    "    print(f\"\\n {name} Metrics:\")\n",
    "    print(f\"Accuracy:  {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"F1 Score:  {f1_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Recall:    {recall_score(y_true, y_pred):.4f}\")\n",
    "\n",
    "print_metrics(all_true_adhd, adhd_pred_labels, \"ADHD\")\n",
    "print_metrics(all_true_sex, sex_pred_labels, \"Sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ff730c724912fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T22:42:29.805042Z",
     "start_time": "2025-04-19T22:42:29.801744Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
