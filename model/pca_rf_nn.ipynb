{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14649cef",
   "metadata": {},
   "source": [
    "### Load in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a73ebe7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T01:08:37.826354Z",
     "start_time": "2025-04-22T01:08:21.485818Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Use read_excel and use participant_id as the index\n",
    "train_cat = pd.read_excel(\n",
    "    \"../../widsdatathon2025/TRAIN_NEW/TRAIN_CATEGORICAL_METADATA_new.xlsx\")\n",
    "train_func = pd.read_csv(\"../../widsdatathon2025/TRAIN_NEW/\"\n",
    "                         \"TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv\")\n",
    "train_quant = pd.read_excel(\n",
    "    \"../../widsdatathon2025/TRAIN_NEW/TRAIN_QUANTITATIVE_METADATA_new.xlsx\")\n",
    "train_soln = pd.read_excel(\n",
    "    \"../../widsdatathon2025/TRAIN_NEW/TRAINING_SOLUTIONS.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d5a6a6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T01:09:41.280012Z",
     "start_time": "2025-04-22T01:09:39.947578Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['participant_id'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/l9/v78y7h896278tzntj74hkdkr0000gn/T/ipykernel_25266/1396164624.py\u001B[0m in \u001B[0;36m?\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Set index for merging\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mtrain_cat\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"participant_id\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minplace\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mtrain_quant\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"participant_id\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minplace\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mtrain_func\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"participant_id\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minplace\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mtrain_soln\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"participant_id\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minplace\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001B[0m\n\u001B[1;32m   6118\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mfound\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6119\u001B[0m                         \u001B[0mmissing\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcol\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6120\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6121\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mmissing\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 6122\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"None of {missing} are in the columns\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   6123\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6124\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0minplace\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6125\u001B[0m             \u001B[0mframe\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: \"None of ['participant_id'] are in the columns\""
     ]
    }
   ],
   "source": [
    "# Set index for merging\n",
    "train_cat.set_index(\"participant_id\", inplace=True)\n",
    "train_quant.set_index(\"participant_id\", inplace=True)\n",
    "train_func.set_index(\"participant_id\", inplace=True)\n",
    "train_soln.set_index(\"participant_id\", inplace=True)\n",
    "\n",
    "# train_cat.head()\n",
    "# train_func.head()\n",
    "# train_quant.head()\n",
    "# train_soln.head()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                0throw_1thcolumn  0throw_2thcolumn  0throw_3thcolumn  \\\nparticipant_id                                                         \n70z8Q2xdTXM3            0.222930          0.527903          0.429966   \nWHWymJu6zNZi            0.614765          0.577255          0.496127   \n4PAQp1M6EyAo           -0.116833          0.458408          0.260703   \nobEacy4Of68I            0.199688          0.752714          0.658283   \ns7WzzDcmDOhF            0.227321          0.613268          0.621447   \n...                          ...               ...               ...   \n9gpepMI9sj5q            0.265284          0.551726          0.628318   \nFIDen5rdMc0v           -0.018377          0.576689          0.527451   \ndlsMC4TXL4e8            0.227028          0.405659          0.023545   \nsyeyZjEx8FUx            0.189849          0.752876          0.842463   \nwWZUoBUOOXhT            0.165500          0.779444          0.686992   \n\n                0throw_4thcolumn  0throw_5thcolumn  0throw_6thcolumn  \\\nparticipant_id                                                         \n70z8Q2xdTXM3            0.060457          0.566489          0.315342   \nWHWymJu6zNZi            0.496606          0.404686          0.439724   \n4PAQp1M6EyAo            0.639031          0.769337          0.442528   \nobEacy4Of68I            0.575096          0.692867          0.645789   \ns7WzzDcmDOhF            0.562673          0.736709          0.589813   \n...                          ...               ...               ...   \n9gpepMI9sj5q            0.647700          0.710757          0.132334   \nFIDen5rdMc0v            0.327463          0.586868          0.573689   \ndlsMC4TXL4e8           -0.093085         -0.068960          0.647574   \nsyeyZjEx8FUx            0.817037          0.820196          0.792950   \nwWZUoBUOOXhT            0.723378          0.747767          0.616990   \n\n                0throw_7thcolumn  0throw_8thcolumn  0throw_9thcolumn  \\\nparticipant_id                                                         \n70z8Q2xdTXM3            0.508408         -0.078290          0.525692   \nWHWymJu6zNZi            0.122590         -0.085452          0.120673   \n4PAQp1M6EyAo            0.637110          0.192010          0.520379   \nobEacy4Of68I            0.522750          0.412188          0.530843   \ns7WzzDcmDOhF            0.266676          0.359668          0.300771   \n...                          ...               ...               ...   \n9gpepMI9sj5q            0.326207          0.354319          0.531170   \nFIDen5rdMc0v            0.300544          0.301103          0.659840   \ndlsMC4TXL4e8            0.762552          0.465109          0.199337   \nsyeyZjEx8FUx            0.650929          0.488504          0.580207   \nwWZUoBUOOXhT            0.513525          0.301234          0.392071   \n\n                0throw_10thcolumn  ...  195throw_196thcolumn  \\\nparticipant_id                     ...                         \n70z8Q2xdTXM3             0.470063  ...              0.224985   \nWHWymJu6zNZi             0.276350  ...              0.217546   \n4PAQp1M6EyAo             0.378557  ...              0.342487   \nobEacy4Of68I             0.259596  ...              0.103562   \ns7WzzDcmDOhF             0.331445  ...             -0.164956   \n...                           ...  ...                   ...   \n9gpepMI9sj5q             0.340388  ...              0.127097   \nFIDen5rdMc0v             0.434427  ...              0.482214   \ndlsMC4TXL4e8            -0.357953  ...             -0.379304   \nsyeyZjEx8FUx             0.162963  ...             -0.212254   \nwWZUoBUOOXhT             0.075941  ...             -0.185250   \n\n                195throw_197thcolumn  195throw_198thcolumn  \\\nparticipant_id                                               \n70z8Q2xdTXM3                0.397448              0.422966   \nWHWymJu6zNZi               -0.014549              0.000440   \n4PAQp1M6EyAo               -0.021141             -0.037836   \nobEacy4Of68I               -0.178313              0.210983   \ns7WzzDcmDOhF                0.007064             -0.120904   \n...                              ...                   ...   \n9gpepMI9sj5q                0.129787              0.298987   \nFIDen5rdMc0v               -0.159587             -0.162498   \ndlsMC4TXL4e8                0.126976              0.193695   \nsyeyZjEx8FUx               -0.055539             -0.221935   \nwWZUoBUOOXhT               -0.290530             -0.276083   \n\n                195throw_199thcolumn  196throw_197thcolumn  \\\nparticipant_id                                               \n70z8Q2xdTXM3                0.184642              0.305549   \nWHWymJu6zNZi               -0.096451              0.454501   \n4PAQp1M6EyAo                0.075069              0.412712   \nobEacy4Of68I               -0.018666              0.436313   \ns7WzzDcmDOhF               -0.488095              0.493575   \n...                              ...                   ...   \n9gpepMI9sj5q                0.114577              0.534109   \nFIDen5rdMc0v               -0.093249              0.309914   \ndlsMC4TXL4e8                0.214483              0.429836   \nsyeyZjEx8FUx               -0.202464              0.602651   \nwWZUoBUOOXhT               -0.384149              0.626095   \n\n                196throw_198thcolumn  196throw_199thcolumn  \\\nparticipant_id                                               \n70z8Q2xdTXM3                0.420349              0.016328   \nWHWymJu6zNZi                0.343916              0.167313   \n4PAQp1M6EyAo                0.292708              0.391005   \nobEacy4Of68I                0.592982              0.216205   \ns7WzzDcmDOhF               -0.215361              0.210685   \n...                              ...                   ...   \n9gpepMI9sj5q                0.118893              0.181292   \nFIDen5rdMc0v                0.143818              0.218337   \ndlsMC4TXL4e8                0.302141              0.104774   \nsyeyZjEx8FUx                0.482066              0.399363   \nwWZUoBUOOXhT                0.664824              0.587586   \n\n                197throw_198thcolumn  197throw_199thcolumn  \\\nparticipant_id                                               \n70z8Q2xdTXM3                0.561864              0.471170   \nWHWymJu6zNZi                0.607656              0.550623   \n4PAQp1M6EyAo                0.461544              0.508912   \nobEacy4Of68I                0.341272              0.440313   \ns7WzzDcmDOhF                0.055850              0.119065   \n...                              ...                   ...   \n9gpepMI9sj5q                0.181055              0.238357   \nFIDen5rdMc0v                0.389331              0.328741   \ndlsMC4TXL4e8                0.856375              0.303248   \nsyeyZjEx8FUx                0.373746              0.279900   \nwWZUoBUOOXhT                0.704292              0.799295   \n\n                198throw_199thcolumn  \nparticipant_id                        \n70z8Q2xdTXM3                0.365221  \nWHWymJu6zNZi                0.503176  \n4PAQp1M6EyAo                0.624232  \nobEacy4Of68I                0.558193  \ns7WzzDcmDOhF                0.108273  \n...                              ...  \n9gpepMI9sj5q                0.577009  \nFIDen5rdMc0v                0.238443  \ndlsMC4TXL4e8                0.363639  \nsyeyZjEx8FUx                0.684434  \nwWZUoBUOOXhT                0.653542  \n\n[1213 rows x 19900 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0throw_1thcolumn</th>\n      <th>0throw_2thcolumn</th>\n      <th>0throw_3thcolumn</th>\n      <th>0throw_4thcolumn</th>\n      <th>0throw_5thcolumn</th>\n      <th>0throw_6thcolumn</th>\n      <th>0throw_7thcolumn</th>\n      <th>0throw_8thcolumn</th>\n      <th>0throw_9thcolumn</th>\n      <th>0throw_10thcolumn</th>\n      <th>...</th>\n      <th>195throw_196thcolumn</th>\n      <th>195throw_197thcolumn</th>\n      <th>195throw_198thcolumn</th>\n      <th>195throw_199thcolumn</th>\n      <th>196throw_197thcolumn</th>\n      <th>196throw_198thcolumn</th>\n      <th>196throw_199thcolumn</th>\n      <th>197throw_198thcolumn</th>\n      <th>197throw_199thcolumn</th>\n      <th>198throw_199thcolumn</th>\n    </tr>\n    <tr>\n      <th>participant_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>70z8Q2xdTXM3</th>\n      <td>0.222930</td>\n      <td>0.527903</td>\n      <td>0.429966</td>\n      <td>0.060457</td>\n      <td>0.566489</td>\n      <td>0.315342</td>\n      <td>0.508408</td>\n      <td>-0.078290</td>\n      <td>0.525692</td>\n      <td>0.470063</td>\n      <td>...</td>\n      <td>0.224985</td>\n      <td>0.397448</td>\n      <td>0.422966</td>\n      <td>0.184642</td>\n      <td>0.305549</td>\n      <td>0.420349</td>\n      <td>0.016328</td>\n      <td>0.561864</td>\n      <td>0.471170</td>\n      <td>0.365221</td>\n    </tr>\n    <tr>\n      <th>WHWymJu6zNZi</th>\n      <td>0.614765</td>\n      <td>0.577255</td>\n      <td>0.496127</td>\n      <td>0.496606</td>\n      <td>0.404686</td>\n      <td>0.439724</td>\n      <td>0.122590</td>\n      <td>-0.085452</td>\n      <td>0.120673</td>\n      <td>0.276350</td>\n      <td>...</td>\n      <td>0.217546</td>\n      <td>-0.014549</td>\n      <td>0.000440</td>\n      <td>-0.096451</td>\n      <td>0.454501</td>\n      <td>0.343916</td>\n      <td>0.167313</td>\n      <td>0.607656</td>\n      <td>0.550623</td>\n      <td>0.503176</td>\n    </tr>\n    <tr>\n      <th>4PAQp1M6EyAo</th>\n      <td>-0.116833</td>\n      <td>0.458408</td>\n      <td>0.260703</td>\n      <td>0.639031</td>\n      <td>0.769337</td>\n      <td>0.442528</td>\n      <td>0.637110</td>\n      <td>0.192010</td>\n      <td>0.520379</td>\n      <td>0.378557</td>\n      <td>...</td>\n      <td>0.342487</td>\n      <td>-0.021141</td>\n      <td>-0.037836</td>\n      <td>0.075069</td>\n      <td>0.412712</td>\n      <td>0.292708</td>\n      <td>0.391005</td>\n      <td>0.461544</td>\n      <td>0.508912</td>\n      <td>0.624232</td>\n    </tr>\n    <tr>\n      <th>obEacy4Of68I</th>\n      <td>0.199688</td>\n      <td>0.752714</td>\n      <td>0.658283</td>\n      <td>0.575096</td>\n      <td>0.692867</td>\n      <td>0.645789</td>\n      <td>0.522750</td>\n      <td>0.412188</td>\n      <td>0.530843</td>\n      <td>0.259596</td>\n      <td>...</td>\n      <td>0.103562</td>\n      <td>-0.178313</td>\n      <td>0.210983</td>\n      <td>-0.018666</td>\n      <td>0.436313</td>\n      <td>0.592982</td>\n      <td>0.216205</td>\n      <td>0.341272</td>\n      <td>0.440313</td>\n      <td>0.558193</td>\n    </tr>\n    <tr>\n      <th>s7WzzDcmDOhF</th>\n      <td>0.227321</td>\n      <td>0.613268</td>\n      <td>0.621447</td>\n      <td>0.562673</td>\n      <td>0.736709</td>\n      <td>0.589813</td>\n      <td>0.266676</td>\n      <td>0.359668</td>\n      <td>0.300771</td>\n      <td>0.331445</td>\n      <td>...</td>\n      <td>-0.164956</td>\n      <td>0.007064</td>\n      <td>-0.120904</td>\n      <td>-0.488095</td>\n      <td>0.493575</td>\n      <td>-0.215361</td>\n      <td>0.210685</td>\n      <td>0.055850</td>\n      <td>0.119065</td>\n      <td>0.108273</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9gpepMI9sj5q</th>\n      <td>0.265284</td>\n      <td>0.551726</td>\n      <td>0.628318</td>\n      <td>0.647700</td>\n      <td>0.710757</td>\n      <td>0.132334</td>\n      <td>0.326207</td>\n      <td>0.354319</td>\n      <td>0.531170</td>\n      <td>0.340388</td>\n      <td>...</td>\n      <td>0.127097</td>\n      <td>0.129787</td>\n      <td>0.298987</td>\n      <td>0.114577</td>\n      <td>0.534109</td>\n      <td>0.118893</td>\n      <td>0.181292</td>\n      <td>0.181055</td>\n      <td>0.238357</td>\n      <td>0.577009</td>\n    </tr>\n    <tr>\n      <th>FIDen5rdMc0v</th>\n      <td>-0.018377</td>\n      <td>0.576689</td>\n      <td>0.527451</td>\n      <td>0.327463</td>\n      <td>0.586868</td>\n      <td>0.573689</td>\n      <td>0.300544</td>\n      <td>0.301103</td>\n      <td>0.659840</td>\n      <td>0.434427</td>\n      <td>...</td>\n      <td>0.482214</td>\n      <td>-0.159587</td>\n      <td>-0.162498</td>\n      <td>-0.093249</td>\n      <td>0.309914</td>\n      <td>0.143818</td>\n      <td>0.218337</td>\n      <td>0.389331</td>\n      <td>0.328741</td>\n      <td>0.238443</td>\n    </tr>\n    <tr>\n      <th>dlsMC4TXL4e8</th>\n      <td>0.227028</td>\n      <td>0.405659</td>\n      <td>0.023545</td>\n      <td>-0.093085</td>\n      <td>-0.068960</td>\n      <td>0.647574</td>\n      <td>0.762552</td>\n      <td>0.465109</td>\n      <td>0.199337</td>\n      <td>-0.357953</td>\n      <td>...</td>\n      <td>-0.379304</td>\n      <td>0.126976</td>\n      <td>0.193695</td>\n      <td>0.214483</td>\n      <td>0.429836</td>\n      <td>0.302141</td>\n      <td>0.104774</td>\n      <td>0.856375</td>\n      <td>0.303248</td>\n      <td>0.363639</td>\n    </tr>\n    <tr>\n      <th>syeyZjEx8FUx</th>\n      <td>0.189849</td>\n      <td>0.752876</td>\n      <td>0.842463</td>\n      <td>0.817037</td>\n      <td>0.820196</td>\n      <td>0.792950</td>\n      <td>0.650929</td>\n      <td>0.488504</td>\n      <td>0.580207</td>\n      <td>0.162963</td>\n      <td>...</td>\n      <td>-0.212254</td>\n      <td>-0.055539</td>\n      <td>-0.221935</td>\n      <td>-0.202464</td>\n      <td>0.602651</td>\n      <td>0.482066</td>\n      <td>0.399363</td>\n      <td>0.373746</td>\n      <td>0.279900</td>\n      <td>0.684434</td>\n    </tr>\n    <tr>\n      <th>wWZUoBUOOXhT</th>\n      <td>0.165500</td>\n      <td>0.779444</td>\n      <td>0.686992</td>\n      <td>0.723378</td>\n      <td>0.747767</td>\n      <td>0.616990</td>\n      <td>0.513525</td>\n      <td>0.301234</td>\n      <td>0.392071</td>\n      <td>0.075941</td>\n      <td>...</td>\n      <td>-0.185250</td>\n      <td>-0.290530</td>\n      <td>-0.276083</td>\n      <td>-0.384149</td>\n      <td>0.626095</td>\n      <td>0.664824</td>\n      <td>0.587586</td>\n      <td>0.704292</td>\n      <td>0.799295</td>\n      <td>0.653542</td>\n    </tr>\n  </tbody>\n</table>\n<p>1213 rows × 19900 columns</p>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_func"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-22T01:10:06.153845Z",
     "start_time": "2025-04-22T01:10:06.003991Z"
    }
   },
   "id": "fd5a7b91f88e16c7",
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "406df64c16f6625a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## PCA for the functional connectome matrix to reduce dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac7849a1151a7af0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:09:39.028330Z",
     "start_time": "2025-04-21T03:09:29.167756Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                fmri_pca_1  fmri_pca_2  fmri_pca_3  fmri_pca_4  fmri_pca_5  \\\nparticipant_id                                                               \n70z8Q2xdTXM3      6.322800   -0.365680   -4.918161   -3.823232   -5.706923   \nWHWymJu6zNZi      5.468294   -3.985252    1.542399    0.104717   -0.529034   \n4PAQp1M6EyAo      0.447190    0.733000    3.051331    1.763901    1.932821   \nobEacy4Of68I     -9.149799   -2.044626    0.519359   -2.703924   -4.444127   \ns7WzzDcmDOhF      0.812814   -1.933265    1.834524    0.383157   -0.512338   \n\n                fmri_pca_6  fmri_pca_7  fmri_pca_8  fmri_pca_9  fmri_pca_10  \\\nparticipant_id                                                                \n70z8Q2xdTXM3     -0.875162    1.567530   -1.347508   -1.717423     1.626893   \nWHWymJu6zNZi     -2.951968    0.786364    0.794950   -2.772031    -2.408772   \n4PAQp1M6EyAo      6.451158   -3.356873    1.946055   -1.165651    -2.876763   \nobEacy4Of68I      2.916930    1.036388    0.080339   -0.148149     0.384162   \ns7WzzDcmDOhF      2.972217    3.151061    3.419844    0.283717    -2.997755   \n\n                ...  fmri_pca_41  fmri_pca_42  fmri_pca_43  fmri_pca_44  \\\nparticipant_id  ...                                                       \n70z8Q2xdTXM3    ...     0.297614     0.753887     0.131417    -0.673929   \nWHWymJu6zNZi    ...     1.083195    -0.565174    -0.865164    -0.010423   \n4PAQp1M6EyAo    ...    -2.385806     0.175190     2.185090     0.656177   \nobEacy4Of68I    ...    -0.169952     1.633509     0.578319    -0.607735   \ns7WzzDcmDOhF    ...     2.802717     2.170408    -2.237547    -0.435744   \n\n                fmri_pca_45  fmri_pca_46  fmri_pca_47  fmri_pca_48  \\\nparticipant_id                                                       \n70z8Q2xdTXM3       2.742455    -4.644635     0.882842     0.345077   \nWHWymJu6zNZi      -2.180346    -0.462796    -1.177160    -0.183711   \n4PAQp1M6EyAo      -0.046917    -2.072229    -1.420524     1.101046   \nobEacy4Of68I      -0.821945    -0.808040    -0.109338    -0.253096   \ns7WzzDcmDOhF      -0.823936     1.265570    -0.043517     2.269485   \n\n                fmri_pca_49  fmri_pca_50  \nparticipant_id                            \n70z8Q2xdTXM3      -0.807577    -0.833189  \nWHWymJu6zNZi      -0.411178     1.614361  \n4PAQp1M6EyAo      -1.340174     2.992421  \nobEacy4Of68I       0.441194    -0.409980  \ns7WzzDcmDOhF      -0.268276    -0.199811  \n\n[5 rows x 50 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fmri_pca_1</th>\n      <th>fmri_pca_2</th>\n      <th>fmri_pca_3</th>\n      <th>fmri_pca_4</th>\n      <th>fmri_pca_5</th>\n      <th>fmri_pca_6</th>\n      <th>fmri_pca_7</th>\n      <th>fmri_pca_8</th>\n      <th>fmri_pca_9</th>\n      <th>fmri_pca_10</th>\n      <th>...</th>\n      <th>fmri_pca_41</th>\n      <th>fmri_pca_42</th>\n      <th>fmri_pca_43</th>\n      <th>fmri_pca_44</th>\n      <th>fmri_pca_45</th>\n      <th>fmri_pca_46</th>\n      <th>fmri_pca_47</th>\n      <th>fmri_pca_48</th>\n      <th>fmri_pca_49</th>\n      <th>fmri_pca_50</th>\n    </tr>\n    <tr>\n      <th>participant_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>70z8Q2xdTXM3</th>\n      <td>6.322800</td>\n      <td>-0.365680</td>\n      <td>-4.918161</td>\n      <td>-3.823232</td>\n      <td>-5.706923</td>\n      <td>-0.875162</td>\n      <td>1.567530</td>\n      <td>-1.347508</td>\n      <td>-1.717423</td>\n      <td>1.626893</td>\n      <td>...</td>\n      <td>0.297614</td>\n      <td>0.753887</td>\n      <td>0.131417</td>\n      <td>-0.673929</td>\n      <td>2.742455</td>\n      <td>-4.644635</td>\n      <td>0.882842</td>\n      <td>0.345077</td>\n      <td>-0.807577</td>\n      <td>-0.833189</td>\n    </tr>\n    <tr>\n      <th>WHWymJu6zNZi</th>\n      <td>5.468294</td>\n      <td>-3.985252</td>\n      <td>1.542399</td>\n      <td>0.104717</td>\n      <td>-0.529034</td>\n      <td>-2.951968</td>\n      <td>0.786364</td>\n      <td>0.794950</td>\n      <td>-2.772031</td>\n      <td>-2.408772</td>\n      <td>...</td>\n      <td>1.083195</td>\n      <td>-0.565174</td>\n      <td>-0.865164</td>\n      <td>-0.010423</td>\n      <td>-2.180346</td>\n      <td>-0.462796</td>\n      <td>-1.177160</td>\n      <td>-0.183711</td>\n      <td>-0.411178</td>\n      <td>1.614361</td>\n    </tr>\n    <tr>\n      <th>4PAQp1M6EyAo</th>\n      <td>0.447190</td>\n      <td>0.733000</td>\n      <td>3.051331</td>\n      <td>1.763901</td>\n      <td>1.932821</td>\n      <td>6.451158</td>\n      <td>-3.356873</td>\n      <td>1.946055</td>\n      <td>-1.165651</td>\n      <td>-2.876763</td>\n      <td>...</td>\n      <td>-2.385806</td>\n      <td>0.175190</td>\n      <td>2.185090</td>\n      <td>0.656177</td>\n      <td>-0.046917</td>\n      <td>-2.072229</td>\n      <td>-1.420524</td>\n      <td>1.101046</td>\n      <td>-1.340174</td>\n      <td>2.992421</td>\n    </tr>\n    <tr>\n      <th>obEacy4Of68I</th>\n      <td>-9.149799</td>\n      <td>-2.044626</td>\n      <td>0.519359</td>\n      <td>-2.703924</td>\n      <td>-4.444127</td>\n      <td>2.916930</td>\n      <td>1.036388</td>\n      <td>0.080339</td>\n      <td>-0.148149</td>\n      <td>0.384162</td>\n      <td>...</td>\n      <td>-0.169952</td>\n      <td>1.633509</td>\n      <td>0.578319</td>\n      <td>-0.607735</td>\n      <td>-0.821945</td>\n      <td>-0.808040</td>\n      <td>-0.109338</td>\n      <td>-0.253096</td>\n      <td>0.441194</td>\n      <td>-0.409980</td>\n    </tr>\n    <tr>\n      <th>s7WzzDcmDOhF</th>\n      <td>0.812814</td>\n      <td>-1.933265</td>\n      <td>1.834524</td>\n      <td>0.383157</td>\n      <td>-0.512338</td>\n      <td>2.972217</td>\n      <td>3.151061</td>\n      <td>3.419844</td>\n      <td>0.283717</td>\n      <td>-2.997755</td>\n      <td>...</td>\n      <td>2.802717</td>\n      <td>2.170408</td>\n      <td>-2.237547</td>\n      <td>-0.435744</td>\n      <td>-0.823936</td>\n      <td>1.265570</td>\n      <td>-0.043517</td>\n      <td>2.269485</td>\n      <td>-0.268276</td>\n      <td>-0.199811</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 50 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Select only fMRI columns\n",
    "fmri_data = train_func.drop(columns=['participant_id'], errors='ignore')\n",
    "\n",
    "# Apply PCA to reduce to top N components (e.g. 50)\n",
    "pca = PCA(n_components=50)\n",
    "fmri_pca = pca.fit_transform(fmri_data)\n",
    "\n",
    "train_func_pca = pd.DataFrame(fmri_pca, index=train_func.index,\n",
    "                           columns=[f'fmri_pca_{i}' for i in range(1, 51)])\n",
    "train_func_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a5a24f4a19a842",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Interpolate missing values with mean for quant and cat dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea3161a9934e682c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:09:39.075964Z",
     "start_time": "2025-04-21T03:09:39.033050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in train_quant:\n",
      " EHQ_EHQ_Total                  13\n",
      "ColorVision_CV_Score           23\n",
      "APQ_P_APQ_P_CP                 12\n",
      "APQ_P_APQ_P_ID                 12\n",
      "APQ_P_APQ_P_INV                12\n",
      "APQ_P_APQ_P_OPD                12\n",
      "APQ_P_APQ_P_PM                 12\n",
      "APQ_P_APQ_P_PP                 12\n",
      "SDQ_SDQ_Conduct_Problems        9\n",
      "SDQ_SDQ_Difficulties_Total      9\n",
      "SDQ_SDQ_Emotional_Problems      9\n",
      "SDQ_SDQ_Externalizing           9\n",
      "SDQ_SDQ_Generating_Impact       9\n",
      "SDQ_SDQ_Hyperactivity           9\n",
      "SDQ_SDQ_Internalizing           9\n",
      "SDQ_SDQ_Peer_Problems           9\n",
      "SDQ_SDQ_Prosocial               9\n",
      "MRI_Track_Age_at_Scan         360\n",
      "dtype: int64\n",
      "Missing values in train_cat:\n",
      " PreInt_Demos_Fam_Child_Ethnicity     43\n",
      "PreInt_Demos_Fam_Child_Race          54\n",
      "MRI_Track_Scan_Location               3\n",
      "Barratt_Barratt_P1_Edu               15\n",
      "Barratt_Barratt_P1_Occ               31\n",
      "Barratt_Barratt_P2_Edu              198\n",
      "Barratt_Barratt_P2_Occ              222\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check missing values *before* merging\n",
    "missing = train_quant.isnull().sum()\n",
    "missing_cat = train_cat.isnull().sum()\n",
    "print(\"Missing values in train_quant:\\n\", missing[missing > 0])\n",
    "print(\"Missing values in train_cat:\\n\", missing_cat[missing_cat > 0])\n",
    "\n",
    "# Define columns with small gaps to impute\n",
    "small_gap_cols = [\n",
    "    'EHQ_EHQ_Total', 'ColorVision_CV_Score',\n",
    "    'APQ_P_APQ_P_CP', 'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV',\n",
    "    'APQ_P_APQ_P_OPD', 'APQ_P_APQ_P_PM', 'APQ_P_APQ_P_PP',\n",
    "    'SDQ_SDQ_Conduct_Problems', 'SDQ_SDQ_Difficulties_Total',\n",
    "    'SDQ_SDQ_Emotional_Problems', 'SDQ_SDQ_Externalizing',\n",
    "    'SDQ_SDQ_Generating_Impact', 'SDQ_SDQ_Hyperactivity',\n",
    "    'SDQ_SDQ_Internalizing', 'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial',\n",
    "    'PreInt_Demos_Fam_Child_Ethnicity', 'PreInt_Demos_Fam_Child_Race',\n",
    "    'MRI_Track_Scan_Location'\n",
    "]\n",
    "\n",
    "small_gap_cols_cat = [\n",
    "    'Barratt_Barratt_P1_Edu', 'Barratt_Barratt_P1_Occ'\n",
    "]\n",
    "\n",
    "# Fill small gaps using column means\n",
    "for col in small_gap_cols:\n",
    "    if col in train_quant.columns:\n",
    "        train_quant[col] = train_quant[col].fillna(train_quant[col].mean())\n",
    "for col in small_gap_cols_cat:\n",
    "    if col in train_cat.columns:\n",
    "        train_cat[col] = train_cat[col].fillna(train_cat[col].mean())\n",
    "\n",
    "train_quant.drop(columns=['MRI_Track_Age_at_Scan'], inplace=True) # Dropped\n",
    "train_cat.drop(columns=['Barratt_Barratt_P2_Occ', 'Barratt_Barratt_P2_Edu'], \n",
    "              inplace=True) # Dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2138a83a91362272",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:09:39.171745Z",
     "start_time": "2025-04-21T03:09:39.050069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in train_quant:\n",
      " Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Check missing values *before* merging\n",
    "missing = train_quant.isnull().sum()\n",
    "print(\"Missing values in train_quant:\\n\", missing[missing > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "268e809ef085e969",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:09:39.215008Z",
     "start_time": "2025-04-21T03:09:39.117950Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                EHQ_EHQ_Total  ColorVision_CV_Score  APQ_P_APQ_P_CP  \\\nparticipant_id                                                        \n00aIpNTbG5uh           100.00                  13.0             3.0   \n00fV0OyyoLfw            92.27                  14.0             3.0   \n04X1eiS79T4B            86.67                  14.0             3.0   \n05ocQutkURd6            93.34                  14.0             3.0   \n06YUNBA9ZRLq             0.00                  14.0             8.0   \n\n                APQ_P_APQ_P_ID  APQ_P_APQ_P_INV  APQ_P_APQ_P_OPD  \\\nparticipant_id                                                     \n00aIpNTbG5uh              15.0             44.0             14.0   \n00fV0OyyoLfw              12.0             35.0             25.0   \n04X1eiS79T4B              21.0             37.0             18.0   \n05ocQutkURd6              11.0             42.0             15.0   \n06YUNBA9ZRLq              12.0             35.0             22.0   \n\n                APQ_P_APQ_P_PM  APQ_P_APQ_P_PP  SDQ_SDQ_Conduct_Problems  \\\nparticipant_id                                                             \n00aIpNTbG5uh              20.0            27.0                       3.0   \n00fV0OyyoLfw              28.0            30.0                       5.0   \n04X1eiS79T4B              26.0            28.0                       3.0   \n05ocQutkURd6              20.0            28.0                       0.0   \n06YUNBA9ZRLq              12.0            24.0                       6.0   \n\n                SDQ_SDQ_Difficulties_Total  SDQ_SDQ_Emotional_Problems  \\\nparticipant_id                                                           \n00aIpNTbG5uh                          17.0                         4.0   \n00fV0OyyoLfw                          20.0                         4.0   \n04X1eiS79T4B                          24.0                         7.0   \n05ocQutkURd6                           5.0                         0.0   \n06YUNBA9ZRLq                          23.0                         7.0   \n\n                SDQ_SDQ_Externalizing  SDQ_SDQ_Generating_Impact  \\\nparticipant_id                                                     \n00aIpNTbG5uh                     11.0                        5.0   \n00fV0OyyoLfw                     13.0                        5.0   \n04X1eiS79T4B                     10.0                       10.0   \n05ocQutkURd6                      3.0                        0.0   \n06YUNBA9ZRLq                     15.0                        8.0   \n\n                SDQ_SDQ_Hyperactivity  SDQ_SDQ_Internalizing  \\\nparticipant_id                                                 \n00aIpNTbG5uh                      8.0                    6.0   \n00fV0OyyoLfw                      8.0                    7.0   \n04X1eiS79T4B                      7.0                   14.0   \n05ocQutkURd6                      3.0                    2.0   \n06YUNBA9ZRLq                      9.0                    8.0   \n\n                SDQ_SDQ_Peer_Problems  SDQ_SDQ_Prosocial  \nparticipant_id                                            \n00aIpNTbG5uh                      2.0                9.0  \n00fV0OyyoLfw                      3.0                8.0  \n04X1eiS79T4B                      7.0                7.0  \n05ocQutkURd6                      2.0                6.0  \n06YUNBA9ZRLq                      1.0                4.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EHQ_EHQ_Total</th>\n      <th>ColorVision_CV_Score</th>\n      <th>APQ_P_APQ_P_CP</th>\n      <th>APQ_P_APQ_P_ID</th>\n      <th>APQ_P_APQ_P_INV</th>\n      <th>APQ_P_APQ_P_OPD</th>\n      <th>APQ_P_APQ_P_PM</th>\n      <th>APQ_P_APQ_P_PP</th>\n      <th>SDQ_SDQ_Conduct_Problems</th>\n      <th>SDQ_SDQ_Difficulties_Total</th>\n      <th>SDQ_SDQ_Emotional_Problems</th>\n      <th>SDQ_SDQ_Externalizing</th>\n      <th>SDQ_SDQ_Generating_Impact</th>\n      <th>SDQ_SDQ_Hyperactivity</th>\n      <th>SDQ_SDQ_Internalizing</th>\n      <th>SDQ_SDQ_Peer_Problems</th>\n      <th>SDQ_SDQ_Prosocial</th>\n    </tr>\n    <tr>\n      <th>participant_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>00aIpNTbG5uh</th>\n      <td>100.00</td>\n      <td>13.0</td>\n      <td>3.0</td>\n      <td>15.0</td>\n      <td>44.0</td>\n      <td>14.0</td>\n      <td>20.0</td>\n      <td>27.0</td>\n      <td>3.0</td>\n      <td>17.0</td>\n      <td>4.0</td>\n      <td>11.0</td>\n      <td>5.0</td>\n      <td>8.0</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>00fV0OyyoLfw</th>\n      <td>92.27</td>\n      <td>14.0</td>\n      <td>3.0</td>\n      <td>12.0</td>\n      <td>35.0</td>\n      <td>25.0</td>\n      <td>28.0</td>\n      <td>30.0</td>\n      <td>5.0</td>\n      <td>20.0</td>\n      <td>4.0</td>\n      <td>13.0</td>\n      <td>5.0</td>\n      <td>8.0</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>04X1eiS79T4B</th>\n      <td>86.67</td>\n      <td>14.0</td>\n      <td>3.0</td>\n      <td>21.0</td>\n      <td>37.0</td>\n      <td>18.0</td>\n      <td>26.0</td>\n      <td>28.0</td>\n      <td>3.0</td>\n      <td>24.0</td>\n      <td>7.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>7.0</td>\n      <td>14.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>05ocQutkURd6</th>\n      <td>93.34</td>\n      <td>14.0</td>\n      <td>3.0</td>\n      <td>11.0</td>\n      <td>42.0</td>\n      <td>15.0</td>\n      <td>20.0</td>\n      <td>28.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>06YUNBA9ZRLq</th>\n      <td>0.00</td>\n      <td>14.0</td>\n      <td>8.0</td>\n      <td>12.0</td>\n      <td>35.0</td>\n      <td>22.0</td>\n      <td>12.0</td>\n      <td>24.0</td>\n      <td>6.0</td>\n      <td>23.0</td>\n      <td>7.0</td>\n      <td>15.0</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_quant.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87099bf1a77809d8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Feature Selection for train_quant using random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f67d283a7b1706d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:09:39.215918Z",
     "start_time": "2025-04-21T03:09:39.133480Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  participant_id  EHQ_EHQ_Total  ColorVision_CV_Score  APQ_P_APQ_P_CP  \\\n0   00aIpNTbG5uh         100.00                  13.0             3.0   \n1   00fV0OyyoLfw          92.27                  14.0             3.0   \n2   04X1eiS79T4B          86.67                  14.0             3.0   \n3   05ocQutkURd6          93.34                  14.0             3.0   \n4   06YUNBA9ZRLq           0.00                  14.0             8.0   \n\n   APQ_P_APQ_P_ID  APQ_P_APQ_P_INV  APQ_P_APQ_P_OPD  APQ_P_APQ_P_PM  \\\n0            15.0             44.0             14.0            20.0   \n1            12.0             35.0             25.0            28.0   \n2            21.0             37.0             18.0            26.0   \n3            11.0             42.0             15.0            20.0   \n4            12.0             35.0             22.0            12.0   \n\n   APQ_P_APQ_P_PP  SDQ_SDQ_Conduct_Problems  SDQ_SDQ_Difficulties_Total  \\\n0            27.0                       3.0                        17.0   \n1            30.0                       5.0                        20.0   \n2            28.0                       3.0                        24.0   \n3            28.0                       0.0                         5.0   \n4            24.0                       6.0                        23.0   \n\n   SDQ_SDQ_Emotional_Problems  SDQ_SDQ_Externalizing  \\\n0                         4.0                   11.0   \n1                         4.0                   13.0   \n2                         7.0                   10.0   \n3                         0.0                    3.0   \n4                         7.0                   15.0   \n\n   SDQ_SDQ_Generating_Impact  SDQ_SDQ_Hyperactivity  SDQ_SDQ_Internalizing  \\\n0                        5.0                    8.0                    6.0   \n1                        5.0                    8.0                    7.0   \n2                       10.0                    7.0                   14.0   \n3                        0.0                    3.0                    2.0   \n4                        8.0                    9.0                    8.0   \n\n   SDQ_SDQ_Peer_Problems  SDQ_SDQ_Prosocial  \n0                    2.0                9.0  \n1                    3.0                8.0  \n2                    7.0                7.0  \n3                    2.0                6.0  \n4                    1.0                4.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>participant_id</th>\n      <th>EHQ_EHQ_Total</th>\n      <th>ColorVision_CV_Score</th>\n      <th>APQ_P_APQ_P_CP</th>\n      <th>APQ_P_APQ_P_ID</th>\n      <th>APQ_P_APQ_P_INV</th>\n      <th>APQ_P_APQ_P_OPD</th>\n      <th>APQ_P_APQ_P_PM</th>\n      <th>APQ_P_APQ_P_PP</th>\n      <th>SDQ_SDQ_Conduct_Problems</th>\n      <th>SDQ_SDQ_Difficulties_Total</th>\n      <th>SDQ_SDQ_Emotional_Problems</th>\n      <th>SDQ_SDQ_Externalizing</th>\n      <th>SDQ_SDQ_Generating_Impact</th>\n      <th>SDQ_SDQ_Hyperactivity</th>\n      <th>SDQ_SDQ_Internalizing</th>\n      <th>SDQ_SDQ_Peer_Problems</th>\n      <th>SDQ_SDQ_Prosocial</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00aIpNTbG5uh</td>\n      <td>100.00</td>\n      <td>13.0</td>\n      <td>3.0</td>\n      <td>15.0</td>\n      <td>44.0</td>\n      <td>14.0</td>\n      <td>20.0</td>\n      <td>27.0</td>\n      <td>3.0</td>\n      <td>17.0</td>\n      <td>4.0</td>\n      <td>11.0</td>\n      <td>5.0</td>\n      <td>8.0</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00fV0OyyoLfw</td>\n      <td>92.27</td>\n      <td>14.0</td>\n      <td>3.0</td>\n      <td>12.0</td>\n      <td>35.0</td>\n      <td>25.0</td>\n      <td>28.0</td>\n      <td>30.0</td>\n      <td>5.0</td>\n      <td>20.0</td>\n      <td>4.0</td>\n      <td>13.0</td>\n      <td>5.0</td>\n      <td>8.0</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>04X1eiS79T4B</td>\n      <td>86.67</td>\n      <td>14.0</td>\n      <td>3.0</td>\n      <td>21.0</td>\n      <td>37.0</td>\n      <td>18.0</td>\n      <td>26.0</td>\n      <td>28.0</td>\n      <td>3.0</td>\n      <td>24.0</td>\n      <td>7.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>7.0</td>\n      <td>14.0</td>\n      <td>7.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>05ocQutkURd6</td>\n      <td>93.34</td>\n      <td>14.0</td>\n      <td>3.0</td>\n      <td>11.0</td>\n      <td>42.0</td>\n      <td>15.0</td>\n      <td>20.0</td>\n      <td>28.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>06YUNBA9ZRLq</td>\n      <td>0.00</td>\n      <td>14.0</td>\n      <td>8.0</td>\n      <td>12.0</td>\n      <td>35.0</td>\n      <td>22.0</td>\n      <td>12.0</td>\n      <td>24.0</td>\n      <td>6.0</td>\n      <td>23.0</td>\n      <td>7.0</td>\n      <td>15.0</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure participant_id is a column, not the index\n",
    "train_quant = train_quant.reset_index()\n",
    "train_cat = train_cat.reset_index()\n",
    "train_soln = train_soln.reset_index()\n",
    "train_quant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d938a182655bc022",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:09:39.217449Z",
     "start_time": "2025-04-21T03:09:39.154662Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  participant_id  Basic_Demos_Enroll_Year  Basic_Demos_Study_Site  \\\n0   00aIpNTbG5uh                     2019                       4   \n1   00fV0OyyoLfw                     2017                       1   \n2   04X1eiS79T4B                     2017                       1   \n3   05ocQutkURd6                     2018                       1   \n4   06YUNBA9ZRLq                     2018                       1   \n\n   PreInt_Demos_Fam_Child_Ethnicity  PreInt_Demos_Fam_Child_Race  \\\n0                               1.0                          0.0   \n1                               0.0                          9.0   \n2                               1.0                          2.0   \n3                               3.0                          8.0   \n4                               0.0                          1.0   \n\n   MRI_Track_Scan_Location  Barratt_Barratt_P1_Edu  Barratt_Barratt_P1_Occ  \n0                      3.0                    21.0                    45.0  \n1                      2.0                    21.0                     0.0  \n2                      2.0                     9.0                     0.0  \n3                      2.0                    18.0                    10.0  \n4                      2.0                    12.0                     0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>participant_id</th>\n      <th>Basic_Demos_Enroll_Year</th>\n      <th>Basic_Demos_Study_Site</th>\n      <th>PreInt_Demos_Fam_Child_Ethnicity</th>\n      <th>PreInt_Demos_Fam_Child_Race</th>\n      <th>MRI_Track_Scan_Location</th>\n      <th>Barratt_Barratt_P1_Edu</th>\n      <th>Barratt_Barratt_P1_Occ</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00aIpNTbG5uh</td>\n      <td>2019</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>21.0</td>\n      <td>45.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00fV0OyyoLfw</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>9.0</td>\n      <td>2.0</td>\n      <td>21.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>04X1eiS79T4B</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>05ocQutkURd6</td>\n      <td>2018</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>8.0</td>\n      <td>2.0</td>\n      <td>18.0</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>06YUNBA9ZRLq</td>\n      <td>2018</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>12.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18c527621fb53507",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:09:39.218972Z",
     "start_time": "2025-04-21T03:09:39.165586Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['SDQ_SDQ_Hyperactivity',\n 'SDQ_SDQ_Internalizing',\n 'SDQ_SDQ_Generating_Impact',\n 'APQ_P_APQ_P_INV',\n 'ColorVision_CV_Score',\n 'APQ_P_APQ_P_CP',\n 'APQ_P_APQ_P_ID',\n 'SDQ_SDQ_Emotional_Problems',\n 'SDQ_SDQ_Conduct_Problems',\n 'SDQ_SDQ_Peer_Problems',\n 'APQ_P_APQ_P_PP',\n 'SDQ_SDQ_Prosocial',\n 'SDQ_SDQ_Externalizing',\n 'APQ_P_APQ_P_OPD',\n 'SDQ_SDQ_Difficulties_Total']"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine with targets temporarily\n",
    "quant_with_targets = train_quant.merge(train_soln[['participant_id', 'ADHD_Outcome',\n",
    "                                                   'Sex_F']], on='participant_id')\n",
    "\n",
    "# Compute correlations\n",
    "corrs = quant_with_targets.drop(columns='participant_id').corr()\n",
    "\n",
    "# Grab correlation with targets\n",
    "adhd_corr = corrs['ADHD_Outcome'].abs().sort_values(ascending=False)\n",
    "sex_corr = corrs['Sex_F'].abs().sort_values(ascending=False)\n",
    "\n",
    "# Keep top N or those above a threshold\n",
    "top_adhd_feats = adhd_corr[adhd_corr > 0.05].index.tolist()\n",
    "top_sex_feats = sex_corr[sex_corr > 0.05].index.tolist()\n",
    "\n",
    "# Union of both sets, drop targets themselves if included\n",
    "quant_selected = list(set(top_adhd_feats + top_sex_feats) - {'ADHD_Outcome', 'Sex_F'})\n",
    "quant_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfff74ffa1b4e36b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:09:39.950203Z",
     "start_time": "2025-04-21T03:09:39.193151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      SDQ_SDQ_Hyperactivity  SDQ_SDQ_Externalizing  fmri_pca_50  \\\n0                       8.0                   11.0     2.962495   \n1                       8.0                   13.0     1.211692   \n2                       7.0                   10.0    -0.577178   \n3                       3.0                    3.0    -0.215200   \n4                       9.0                   15.0    -0.073863   \n...                     ...                    ...          ...   \n1208                    8.0                   13.0    -0.697615   \n1209                    3.0                    5.0     1.523171   \n1210                    7.0                    9.0    -1.530661   \n1211                    7.0                    8.0     2.279119   \n1212                    7.0                    9.0     0.830002   \n\n      SDQ_SDQ_Difficulties_Total  fmri_pca_48  fmri_pca_31  fmri_pca_37  \\\n0                           17.0    -1.168673     1.145635    -1.590348   \n1                           20.0    -0.427006     0.622077    -2.349019   \n2                           24.0    -0.818002     1.623852    -2.521894   \n3                            5.0    -1.276276     0.181463     0.652337   \n4                           23.0    -1.758016     0.042373    -0.122060   \n...                          ...          ...          ...          ...   \n1208                        20.0     1.664023    -1.857924    -0.901934   \n1209                         5.0    -0.986513     1.243697    -0.313522   \n1210                        14.0    -2.140699    -1.024107     2.274901   \n1211                        10.0     2.218683    -2.341829    -5.416851   \n1212                        11.0    -1.992181     0.243799     2.415508   \n\n      fmri_pca_5  fmri_pca_35  fmri_pca_33  ...  fmri_pca_24  fmri_pca_23  \\\n0       0.697012     2.182171     0.400605  ...    -1.097761    -0.680154   \n1      -1.204589     2.248471     2.619120  ...    -0.894607    -0.738267   \n2       1.955186    -0.407818    -0.340320  ...    -1.724498    -1.243957   \n3      -3.212116     1.049282    -1.947907  ...    -0.190874     1.904781   \n4      -0.906084     1.637541    -0.256547  ...    -1.217281    -0.040720   \n...          ...          ...          ...  ...          ...          ...   \n1208    0.328386    -0.711845    -1.979503  ...     0.486715    -1.325598   \n1209    1.456239     0.622894     0.072495  ...    -1.012149     1.459951   \n1210    2.140782     1.598099    -1.626188  ...    -0.866915     2.056705   \n1211   -1.452593     1.097705     2.229249  ...     2.654675     4.084691   \n1212    2.983821    -1.568983     0.573440  ...    -0.673048    -2.261075   \n\n      fmri_pca_42  fmri_pca_11  fmri_pca_32  fmri_pca_43  fmri_pca_29  \\\n0        0.943617     1.281826     6.149201    -1.060490     0.023601   \n1        0.486946     2.213616     0.224037     0.167213    -0.963297   \n2        2.345653    -1.466195    -2.476533    -1.025545    -2.224522   \n3       -0.358380     0.110044    -2.052666     2.735397     1.985295   \n4       -1.529037    -0.895010    -0.168207     0.604799     0.246489   \n...           ...          ...          ...          ...          ...   \n1208     3.151765    -2.206764     2.085514     2.036356    -2.381402   \n1209     0.367025     0.847750    -2.279689     0.093522     0.102984   \n1210    -1.758260     1.057415    -2.228752    -1.749446    -0.637212   \n1211     1.736748     1.646329    -0.709525    -2.210757     0.777506   \n1212     0.167268     4.078795    -0.103322    -1.695868     0.497349   \n\n      fmri_pca_41  fmri_pca_12  fmri_pca_17  \n0        0.750913     1.333274    -1.161215  \n1       -0.777104    -0.086101    -0.787268  \n2        3.813841     3.939671    -4.886952  \n3        1.013148     0.812512    -0.753405  \n4        1.424673    -1.794671    -2.317038  \n...           ...          ...          ...  \n1208     0.610579    -1.016769     1.351153  \n1209     0.174177     1.487577    -0.703363  \n1210    -1.554133    -1.445515     0.980649  \n1211    -2.236938    -5.609986     0.775184  \n1212     0.437531     4.011017     0.232823  \n\n[1213 rows x 50 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SDQ_SDQ_Hyperactivity</th>\n      <th>SDQ_SDQ_Externalizing</th>\n      <th>fmri_pca_50</th>\n      <th>SDQ_SDQ_Difficulties_Total</th>\n      <th>fmri_pca_48</th>\n      <th>fmri_pca_31</th>\n      <th>fmri_pca_37</th>\n      <th>fmri_pca_5</th>\n      <th>fmri_pca_35</th>\n      <th>fmri_pca_33</th>\n      <th>...</th>\n      <th>fmri_pca_24</th>\n      <th>fmri_pca_23</th>\n      <th>fmri_pca_42</th>\n      <th>fmri_pca_11</th>\n      <th>fmri_pca_32</th>\n      <th>fmri_pca_43</th>\n      <th>fmri_pca_29</th>\n      <th>fmri_pca_41</th>\n      <th>fmri_pca_12</th>\n      <th>fmri_pca_17</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8.0</td>\n      <td>11.0</td>\n      <td>2.962495</td>\n      <td>17.0</td>\n      <td>-1.168673</td>\n      <td>1.145635</td>\n      <td>-1.590348</td>\n      <td>0.697012</td>\n      <td>2.182171</td>\n      <td>0.400605</td>\n      <td>...</td>\n      <td>-1.097761</td>\n      <td>-0.680154</td>\n      <td>0.943617</td>\n      <td>1.281826</td>\n      <td>6.149201</td>\n      <td>-1.060490</td>\n      <td>0.023601</td>\n      <td>0.750913</td>\n      <td>1.333274</td>\n      <td>-1.161215</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8.0</td>\n      <td>13.0</td>\n      <td>1.211692</td>\n      <td>20.0</td>\n      <td>-0.427006</td>\n      <td>0.622077</td>\n      <td>-2.349019</td>\n      <td>-1.204589</td>\n      <td>2.248471</td>\n      <td>2.619120</td>\n      <td>...</td>\n      <td>-0.894607</td>\n      <td>-0.738267</td>\n      <td>0.486946</td>\n      <td>2.213616</td>\n      <td>0.224037</td>\n      <td>0.167213</td>\n      <td>-0.963297</td>\n      <td>-0.777104</td>\n      <td>-0.086101</td>\n      <td>-0.787268</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.0</td>\n      <td>10.0</td>\n      <td>-0.577178</td>\n      <td>24.0</td>\n      <td>-0.818002</td>\n      <td>1.623852</td>\n      <td>-2.521894</td>\n      <td>1.955186</td>\n      <td>-0.407818</td>\n      <td>-0.340320</td>\n      <td>...</td>\n      <td>-1.724498</td>\n      <td>-1.243957</td>\n      <td>2.345653</td>\n      <td>-1.466195</td>\n      <td>-2.476533</td>\n      <td>-1.025545</td>\n      <td>-2.224522</td>\n      <td>3.813841</td>\n      <td>3.939671</td>\n      <td>-4.886952</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>-0.215200</td>\n      <td>5.0</td>\n      <td>-1.276276</td>\n      <td>0.181463</td>\n      <td>0.652337</td>\n      <td>-3.212116</td>\n      <td>1.049282</td>\n      <td>-1.947907</td>\n      <td>...</td>\n      <td>-0.190874</td>\n      <td>1.904781</td>\n      <td>-0.358380</td>\n      <td>0.110044</td>\n      <td>-2.052666</td>\n      <td>2.735397</td>\n      <td>1.985295</td>\n      <td>1.013148</td>\n      <td>0.812512</td>\n      <td>-0.753405</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9.0</td>\n      <td>15.0</td>\n      <td>-0.073863</td>\n      <td>23.0</td>\n      <td>-1.758016</td>\n      <td>0.042373</td>\n      <td>-0.122060</td>\n      <td>-0.906084</td>\n      <td>1.637541</td>\n      <td>-0.256547</td>\n      <td>...</td>\n      <td>-1.217281</td>\n      <td>-0.040720</td>\n      <td>-1.529037</td>\n      <td>-0.895010</td>\n      <td>-0.168207</td>\n      <td>0.604799</td>\n      <td>0.246489</td>\n      <td>1.424673</td>\n      <td>-1.794671</td>\n      <td>-2.317038</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1208</th>\n      <td>8.0</td>\n      <td>13.0</td>\n      <td>-0.697615</td>\n      <td>20.0</td>\n      <td>1.664023</td>\n      <td>-1.857924</td>\n      <td>-0.901934</td>\n      <td>0.328386</td>\n      <td>-0.711845</td>\n      <td>-1.979503</td>\n      <td>...</td>\n      <td>0.486715</td>\n      <td>-1.325598</td>\n      <td>3.151765</td>\n      <td>-2.206764</td>\n      <td>2.085514</td>\n      <td>2.036356</td>\n      <td>-2.381402</td>\n      <td>0.610579</td>\n      <td>-1.016769</td>\n      <td>1.351153</td>\n    </tr>\n    <tr>\n      <th>1209</th>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>1.523171</td>\n      <td>5.0</td>\n      <td>-0.986513</td>\n      <td>1.243697</td>\n      <td>-0.313522</td>\n      <td>1.456239</td>\n      <td>0.622894</td>\n      <td>0.072495</td>\n      <td>...</td>\n      <td>-1.012149</td>\n      <td>1.459951</td>\n      <td>0.367025</td>\n      <td>0.847750</td>\n      <td>-2.279689</td>\n      <td>0.093522</td>\n      <td>0.102984</td>\n      <td>0.174177</td>\n      <td>1.487577</td>\n      <td>-0.703363</td>\n    </tr>\n    <tr>\n      <th>1210</th>\n      <td>7.0</td>\n      <td>9.0</td>\n      <td>-1.530661</td>\n      <td>14.0</td>\n      <td>-2.140699</td>\n      <td>-1.024107</td>\n      <td>2.274901</td>\n      <td>2.140782</td>\n      <td>1.598099</td>\n      <td>-1.626188</td>\n      <td>...</td>\n      <td>-0.866915</td>\n      <td>2.056705</td>\n      <td>-1.758260</td>\n      <td>1.057415</td>\n      <td>-2.228752</td>\n      <td>-1.749446</td>\n      <td>-0.637212</td>\n      <td>-1.554133</td>\n      <td>-1.445515</td>\n      <td>0.980649</td>\n    </tr>\n    <tr>\n      <th>1211</th>\n      <td>7.0</td>\n      <td>8.0</td>\n      <td>2.279119</td>\n      <td>10.0</td>\n      <td>2.218683</td>\n      <td>-2.341829</td>\n      <td>-5.416851</td>\n      <td>-1.452593</td>\n      <td>1.097705</td>\n      <td>2.229249</td>\n      <td>...</td>\n      <td>2.654675</td>\n      <td>4.084691</td>\n      <td>1.736748</td>\n      <td>1.646329</td>\n      <td>-0.709525</td>\n      <td>-2.210757</td>\n      <td>0.777506</td>\n      <td>-2.236938</td>\n      <td>-5.609986</td>\n      <td>0.775184</td>\n    </tr>\n    <tr>\n      <th>1212</th>\n      <td>7.0</td>\n      <td>9.0</td>\n      <td>0.830002</td>\n      <td>11.0</td>\n      <td>-1.992181</td>\n      <td>0.243799</td>\n      <td>2.415508</td>\n      <td>2.983821</td>\n      <td>-1.568983</td>\n      <td>0.573440</td>\n      <td>...</td>\n      <td>-0.673048</td>\n      <td>-2.261075</td>\n      <td>0.167268</td>\n      <td>4.078795</td>\n      <td>-0.103322</td>\n      <td>-1.695868</td>\n      <td>0.497349</td>\n      <td>0.437531</td>\n      <td>4.011017</td>\n      <td>0.232823</td>\n    </tr>\n  </tbody>\n</table>\n<p>1213 rows × 50 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Merge everything on participant_id\n",
    "X_full = train_quant[['participant_id'] + quant_selected] \\\n",
    "    .merge(train_cat, on='participant_id') \\\n",
    "    .merge(train_func_pca, on='participant_id')\n",
    "\n",
    "# Target labels\n",
    "y = train_soln[['participant_id', 'ADHD_Outcome', 'Sex_F']]\n",
    "\n",
    "# Align rows across X and y\n",
    "X_full = X_full.merge(y, on='participant_id')\n",
    "y = X_full[['ADHD_Outcome', 'Sex_F']]\n",
    "X_full = X_full.drop(columns=['ADHD_Outcome', 'Sex_F'])\n",
    "\n",
    "# Use combined target just for ranking features\n",
    "combo_target = y['ADHD_Outcome'] + y['Sex_F']\n",
    "\n",
    "# Train the Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_full.drop(columns=['participant_id']), combo_target)\n",
    "\n",
    "# Rank feature importances\n",
    "feat_importances = pd.Series(rf.feature_importances_, index=X_full.drop(columns=['participant_id']).columns)\n",
    "top_features_final = feat_importances.sort_values(ascending=False).head(50).index.tolist()\n",
    "\n",
    "# Final X for model training\n",
    "X_selected = X_full[top_features_final]\n",
    "X_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3597474bf27bb8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:09:42.779583Z",
     "start_time": "2025-04-21T03:09:39.927697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 50.3702 | Val Loss: 1.5962\n",
      "Epoch 2 | Train Loss: 48.3551 | Val Loss: 1.5582\n",
      "Epoch 3 | Train Loss: 47.2033 | Val Loss: 1.5464\n",
      "Epoch 4 | Train Loss: 46.4335 | Val Loss: 1.5311\n",
      "Epoch 5 | Train Loss: 46.0317 | Val Loss: 1.5251\n",
      "Epoch 6 | Train Loss: 45.3612 | Val Loss: 1.5341\n",
      "Epoch 7 | Train Loss: 44.8930 | Val Loss: 1.5375\n",
      "Epoch 8 | Train Loss: 44.6739 | Val Loss: 1.5355\n",
      "Epoch 9 | Train Loss: 44.3715 | Val Loss: 1.5288\n",
      "Epoch 10 | Train Loss: 44.0580 | Val Loss: 1.5379\n",
      "Early stopping triggered.\n",
      "\n",
      "ADHD Weighted F1 Score: 0.8064\n",
      "Sex Weighted F1 Score: 0.4881\n",
      "\n",
      " ADHD Metrics:\n",
      "Accuracy:  0.7654\n",
      "F1 Score:  0.8412\n",
      "Precision: 0.7865\n",
      "Recall:    0.9042\n",
      "\n",
      " Sex Metrics:\n",
      "Accuracy:  0.6296\n",
      "F1 Score:  0.3750\n",
      "Precision: 0.4426\n",
      "Recall:    0.3253\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_selected)\n",
    "\n",
    "# Convert to tensors\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y[['ADHD_Outcome', 'Sex_F']].values, dtype=torch.float32)\n",
    "\n",
    "# Stratified train/test split\n",
    "stratify_labels = y['ADHD_Outcome'].astype(str) + y['Sex_F'].astype(str)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tensor, y_tensor, test_size=0.2, random_state=42, stratify=stratify_labels)\n",
    "\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "test_ds = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=32)\n",
    "\n",
    "# Beefed-up model\n",
    "class BetterMultiOutputNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.head_adhd = nn.Linear(128, 1)\n",
    "        self.head_sex = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shared_out = self.shared(x)\n",
    "        return torch.sigmoid(self.head_adhd(shared_out)), torch.sigmoid(self.head_sex(shared_out))\n",
    "\n",
    "# Weighted BCE Loss with 2x weight for Female ADHD cases\n",
    "class WeightedBCELoss(nn.Module):\n",
    "    def __init__(self, weight_female_adhd=2):\n",
    "        super(WeightedBCELoss, self).__init__()\n",
    "        self.weight_female_adhd = weight_female_adhd\n",
    "\n",
    "    def forward(self, predictions, targets, sex):\n",
    "        # Calculate standard BCE loss\n",
    "        bce_loss = nn.BCEWithLogitsLoss(reduction='none')(predictions, targets)\n",
    "        \n",
    "        # Apply weight for female ADHD cases (ADHD_Outcome=1, Sex_F=1)\n",
    "        weight = torch.ones_like(bce_loss)\n",
    "        weight[(targets == 1) & (sex == 1)] = self.weight_female_adhd\n",
    "        \n",
    "        # Apply the weights to the loss\n",
    "        weighted_loss = weight * bce_loss\n",
    "        return weighted_loss.mean()\n",
    "\n",
    "# Initialize model and loss function\n",
    "model = BetterMultiOutputNN(X_selected.shape[1])\n",
    "weighted_criterion = WeightedBCELoss(weight_female_adhd=2)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n",
    "\n",
    "# Training loop with early stopping\n",
    "best_val_loss = np.inf\n",
    "patience = 5\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for xb, yb in train_loader:\n",
    "        adhd_pred, sex_pred = model(xb)\n",
    "        # Extract ADHD and Sex labels\n",
    "        adhd_labels = yb[:, 0]\n",
    "        sex_labels = yb[:, 1]\n",
    "        \n",
    "        # Compute weighted loss for both ADHD and Sex\n",
    "        loss_adhd = weighted_criterion(adhd_pred.squeeze(), adhd_labels, sex_labels)\n",
    "        loss_sex = weighted_criterion(sex_pred.squeeze(), sex_labels, sex_labels)\n",
    "        \n",
    "        # Total loss\n",
    "        loss = loss_adhd + loss_sex\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            adhd_pred, sex_pred = model(xb)\n",
    "            loss_adhd = weighted_criterion(adhd_pred.squeeze(), yb[:, 0], yb[:, 1])\n",
    "            loss_sex = weighted_criterion(sex_pred.squeeze(), yb[:, 1], yb[:, 1])\n",
    "            val_loss = loss_adhd + loss_sex\n",
    "            val_losses.append(val_loss.item())\n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {running_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_model = model.state_dict()\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# Evaluation\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "all_preds, all_true = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        adhd_pred, sex_pred = model(xb)\n",
    "        preds = torch.cat([adhd_pred, sex_pred], dim=1)\n",
    "        all_preds.append(preds)\n",
    "        all_true.append(yb)\n",
    "\n",
    "all_preds = torch.cat(all_preds).numpy()\n",
    "all_true = torch.cat(all_true).numpy()\n",
    "\n",
    "# Thresholding\n",
    "adhd_pred_labels = (all_preds[:, 0] > 0.5).astype(int)\n",
    "sex_pred_labels = (all_preds[:, 1] > 0.5).astype(int)\n",
    "\n",
    "# Ensure the true labels are correctly handled (indexing properly)\n",
    "all_true_adhd = all_true[:, 0].astype(int)\n",
    "all_true_sex = all_true[:, 1].astype(int)\n",
    "\n",
    "# Compute weighted F1 Score with 2x weight for Female ADHD cases\n",
    "def weighted_f1(y_true, y_pred, weight_column):\n",
    "    # Assign a weight of 2x for Female ADHD cases\n",
    "    weight = np.ones_like(y_true)\n",
    "    weight[(y_true == 1) & (weight_column == 1)] = 3  # Apply 2x weight for Female ADHD\n",
    "    \n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', sample_weight=weight)\n",
    "    return f1\n",
    "\n",
    "f1_adhd = weighted_f1(all_true_adhd, adhd_pred_labels, all_true_sex)\n",
    "f1_sex = weighted_f1(all_true_sex, sex_pred_labels, all_true_sex)\n",
    "\n",
    "print(f\"\\nADHD Weighted F1 Score: {f1_adhd:.4f}\")\n",
    "print(f\"Sex Weighted F1 Score: {f1_sex:.4f}\")\n",
    "\n",
    "# Metrics for ADHD\n",
    "def print_metrics(y_true, y_pred, name):\n",
    "    print(f\"\\n {name} Metrics:\")\n",
    "    print(f\"Accuracy:  {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"F1 Score:  {f1_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Recall:    {recall_score(y_true, y_pred):.4f}\")\n",
    "\n",
    "print_metrics(all_true_adhd, adhd_pred_labels, \"ADHD\")\n",
    "print_metrics(all_true_sex, sex_pred_labels, \"Sex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing and Submission"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1226e02566ee980"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Use read_excel and use participant_id as the index\n",
    "test_cat = pd.read_excel(\"../../widsdatathon2025/TEST/TEST_CATEGORICAL.xlsx\")\n",
    "test_func = pd.read_csv(\"../../widsdatathon2025/TEST/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv\")\n",
    "test_quant = pd.read_excel(\"../../widsdatathon2025/TEST/TEST_QUANTITATIVE_METADATA.xlsx\")\n",
    "solutions_path = \"../../widsdatathon2025/TEST/TEST_SOLUTIONS.xlsx\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T03:17:42.990197Z",
     "start_time": "2025-04-21T03:17:40.874661Z"
    }
   },
   "id": "e6f2115a91900652",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  participant_id  0throw_1thcolumn  0throw_2thcolumn  0throw_3thcolumn  \\\n0   Cfwaf5FX7jWK          0.548480          0.713607          0.557319   \n1   vhGrzmvA3Hjq          0.427740          0.363022          0.402862   \n2   ULliyEXjy4OV          0.139572          0.390106         -0.087041   \n3   LZfeAb1xMtql          0.133561          0.778326          0.416355   \n4   EnFOUv0YK1RG          0.126699          0.575446          0.509422   \n\n   0throw_4thcolumn  0throw_5thcolumn  0throw_6thcolumn  0throw_7thcolumn  \\\n0          0.524369          0.693364          0.770032          0.724406   \n1          0.363003          0.534558          0.345347          0.409471   \n2          0.196852          0.088148          0.023843          0.381782   \n3          0.471840          0.568460          0.633660          0.501113   \n4          0.363193          0.427544          0.449924          0.451796   \n\n   0throw_8thcolumn  0throw_9thcolumn  ...  195throw_196thcolumn  \\\n0          0.390118          0.547912  ...              0.080423   \n1          0.303328          0.402515  ...              0.198009   \n2          0.068979          0.377488  ...              0.051319   \n3          0.345461          0.467943  ...              0.046183   \n4          0.223927          0.298248  ...              0.315734   \n\n   195throw_197thcolumn  195throw_198thcolumn  195throw_199thcolumn  \\\n0             -0.054581             -0.088163             -0.028574   \n1             -0.000724              0.083122              0.033043   \n2              0.023630             -0.056819              0.117396   \n3             -0.238962              0.121868             -0.260970   \n4              0.002234              0.290791              0.344149   \n\n   196throw_197thcolumn  196throw_198thcolumn  196throw_199thcolumn  \\\n0              0.444847              0.350149             -0.012601   \n1              0.687497              0.306229              0.717485   \n2              0.576086              0.517831              0.527044   \n3              0.646818              0.594902              0.608156   \n4              0.480214              0.539824              0.447322   \n\n   197throw_198thcolumn  197throw_199thcolumn  198throw_199thcolumn  \n0              0.665750              0.560565              0.555732  \n1              0.461809              0.559632              0.350027  \n2              0.605038              0.609856              0.750987  \n3              0.595459              0.683189              0.542296  \n4              0.293088              0.148529              0.539823  \n\n[5 rows x 19901 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>participant_id</th>\n      <th>0throw_1thcolumn</th>\n      <th>0throw_2thcolumn</th>\n      <th>0throw_3thcolumn</th>\n      <th>0throw_4thcolumn</th>\n      <th>0throw_5thcolumn</th>\n      <th>0throw_6thcolumn</th>\n      <th>0throw_7thcolumn</th>\n      <th>0throw_8thcolumn</th>\n      <th>0throw_9thcolumn</th>\n      <th>...</th>\n      <th>195throw_196thcolumn</th>\n      <th>195throw_197thcolumn</th>\n      <th>195throw_198thcolumn</th>\n      <th>195throw_199thcolumn</th>\n      <th>196throw_197thcolumn</th>\n      <th>196throw_198thcolumn</th>\n      <th>196throw_199thcolumn</th>\n      <th>197throw_198thcolumn</th>\n      <th>197throw_199thcolumn</th>\n      <th>198throw_199thcolumn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cfwaf5FX7jWK</td>\n      <td>0.548480</td>\n      <td>0.713607</td>\n      <td>0.557319</td>\n      <td>0.524369</td>\n      <td>0.693364</td>\n      <td>0.770032</td>\n      <td>0.724406</td>\n      <td>0.390118</td>\n      <td>0.547912</td>\n      <td>...</td>\n      <td>0.080423</td>\n      <td>-0.054581</td>\n      <td>-0.088163</td>\n      <td>-0.028574</td>\n      <td>0.444847</td>\n      <td>0.350149</td>\n      <td>-0.012601</td>\n      <td>0.665750</td>\n      <td>0.560565</td>\n      <td>0.555732</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>vhGrzmvA3Hjq</td>\n      <td>0.427740</td>\n      <td>0.363022</td>\n      <td>0.402862</td>\n      <td>0.363003</td>\n      <td>0.534558</td>\n      <td>0.345347</td>\n      <td>0.409471</td>\n      <td>0.303328</td>\n      <td>0.402515</td>\n      <td>...</td>\n      <td>0.198009</td>\n      <td>-0.000724</td>\n      <td>0.083122</td>\n      <td>0.033043</td>\n      <td>0.687497</td>\n      <td>0.306229</td>\n      <td>0.717485</td>\n      <td>0.461809</td>\n      <td>0.559632</td>\n      <td>0.350027</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ULliyEXjy4OV</td>\n      <td>0.139572</td>\n      <td>0.390106</td>\n      <td>-0.087041</td>\n      <td>0.196852</td>\n      <td>0.088148</td>\n      <td>0.023843</td>\n      <td>0.381782</td>\n      <td>0.068979</td>\n      <td>0.377488</td>\n      <td>...</td>\n      <td>0.051319</td>\n      <td>0.023630</td>\n      <td>-0.056819</td>\n      <td>0.117396</td>\n      <td>0.576086</td>\n      <td>0.517831</td>\n      <td>0.527044</td>\n      <td>0.605038</td>\n      <td>0.609856</td>\n      <td>0.750987</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LZfeAb1xMtql</td>\n      <td>0.133561</td>\n      <td>0.778326</td>\n      <td>0.416355</td>\n      <td>0.471840</td>\n      <td>0.568460</td>\n      <td>0.633660</td>\n      <td>0.501113</td>\n      <td>0.345461</td>\n      <td>0.467943</td>\n      <td>...</td>\n      <td>0.046183</td>\n      <td>-0.238962</td>\n      <td>0.121868</td>\n      <td>-0.260970</td>\n      <td>0.646818</td>\n      <td>0.594902</td>\n      <td>0.608156</td>\n      <td>0.595459</td>\n      <td>0.683189</td>\n      <td>0.542296</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>EnFOUv0YK1RG</td>\n      <td>0.126699</td>\n      <td>0.575446</td>\n      <td>0.509422</td>\n      <td>0.363193</td>\n      <td>0.427544</td>\n      <td>0.449924</td>\n      <td>0.451796</td>\n      <td>0.223927</td>\n      <td>0.298248</td>\n      <td>...</td>\n      <td>0.315734</td>\n      <td>0.002234</td>\n      <td>0.290791</td>\n      <td>0.344149</td>\n      <td>0.480214</td>\n      <td>0.539824</td>\n      <td>0.447322</td>\n      <td>0.293088</td>\n      <td>0.148529</td>\n      <td>0.539823</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 19901 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set index for merging\n",
    "test_cat.set_index(\"participant_id\", inplace=True)\n",
    "test_quant.set_index(\"participant_id\", inplace=True)\n",
    "test_func.set_index(\"participant_id\", inplace=True)\n",
    "\n",
    "# train_cat.head()\n",
    "train_func.head()\n",
    "# train_quant.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T03:17:50.974945Z",
     "start_time": "2025-04-21T03:17:50.895278Z"
    }
   },
   "id": "7d0cce83e162f93e",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in train_quant:\n",
      " EHQ_EHQ_Total                  1\n",
      "ColorVision_CV_Score           9\n",
      "APQ_P_APQ_P_CP                15\n",
      "APQ_P_APQ_P_ID                15\n",
      "APQ_P_APQ_P_INV               15\n",
      "APQ_P_APQ_P_OPD               15\n",
      "APQ_P_APQ_P_PM                15\n",
      "APQ_P_APQ_P_PP                15\n",
      "SDQ_SDQ_Conduct_Problems      30\n",
      "SDQ_SDQ_Difficulties_Total    30\n",
      "SDQ_SDQ_Emotional_Problems    30\n",
      "SDQ_SDQ_Externalizing         30\n",
      "SDQ_SDQ_Generating_Impact     30\n",
      "SDQ_SDQ_Hyperactivity         30\n",
      "SDQ_SDQ_Internalizing         30\n",
      "SDQ_SDQ_Peer_Problems         30\n",
      "SDQ_SDQ_Prosocial             30\n",
      "dtype: int64\n",
      "Missing values in train_cat:\n",
      " PreInt_Demos_Fam_Child_Ethnicity     3\n",
      "PreInt_Demos_Fam_Child_Race          6\n",
      "Barratt_Barratt_P1_Edu               1\n",
      "Barratt_Barratt_P1_Occ               1\n",
      "Barratt_Barratt_P2_Edu              36\n",
      "Barratt_Barratt_P2_Occ              42\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Select only fMRI columns\n",
    "fmri_data = test_func.drop(columns=['participant_id'], errors='ignore')\n",
    "\n",
    "# Apply PCA to reduce to top N components (e.g. 50)\n",
    "pca = PCA(n_components=50)\n",
    "fmri_pca = pca.fit_transform(fmri_data)\n",
    "\n",
    "test_func_pca = pd.DataFrame(fmri_pca, index=test_func.index,\n",
    "                           columns=[f'fmri_pca_{i}' for i in range(1, 51)])\n",
    "test_func_pca.head()\n",
    "\n",
    "# Check missing values *before* merging\n",
    "missing = test_quant.isnull().sum()\n",
    "missing_cat = test_cat.isnull().sum()\n",
    "print(\"Missing values in train_quant:\\n\", missing[missing > 0])\n",
    "print(\"Missing values in train_cat:\\n\", missing_cat[missing_cat > 0])\n",
    "\n",
    "# Define columns with small gaps to impute\n",
    "small_gap_cols = [\n",
    "    'EHQ_EHQ_Total', 'ColorVision_CV_Score',\n",
    "    'APQ_P_APQ_P_CP', 'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV',\n",
    "    'APQ_P_APQ_P_OPD', 'APQ_P_APQ_P_PM', 'APQ_P_APQ_P_PP',\n",
    "    'SDQ_SDQ_Conduct_Problems', 'SDQ_SDQ_Difficulties_Total',\n",
    "    'SDQ_SDQ_Emotional_Problems', 'SDQ_SDQ_Externalizing',\n",
    "    'SDQ_SDQ_Generating_Impact', 'SDQ_SDQ_Hyperactivity',\n",
    "    'SDQ_SDQ_Internalizing', 'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial',\n",
    "    'PreInt_Demos_Fam_Child_Ethnicity', 'PreInt_Demos_Fam_Child_Race',\n",
    "    'MRI_Track_Scan_Location'\n",
    "]\n",
    "\n",
    "small_gap_cols_cat = [\n",
    "    'Barratt_Barratt_P1_Edu', 'Barratt_Barratt_P1_Occ'\n",
    "]\n",
    "\n",
    "# Fill small gaps using column means\n",
    "for col in small_gap_cols:\n",
    "    if col in test_quant.columns:\n",
    "        test_quant[col] = test_quant[col].fillna(test_quant[col].mean())\n",
    "for col in small_gap_cols_cat:\n",
    "    if col in test_cat.columns:\n",
    "        test_cat[col] = test_cat[col].fillna(test_cat[col].mean())\n",
    "\n",
    "test_quant.drop(columns=['MRI_Track_Age_at_Scan'], inplace=True) # Dropped\n",
    "test_cat.drop(columns=['Barratt_Barratt_P2_Occ', 'Barratt_Barratt_P2_Edu'], \n",
    "              inplace=True) # Dropped\n",
    "\n",
    "# Make sure participant_id is a column, not the index\n",
    "test_quant = test_quant.reset_index()\n",
    "test_cat = test_cat.reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T03:20:36.403525Z",
     "start_time": "2025-04-21T03:20:31.178932Z"
    }
   },
   "id": "cd0694b833f64311",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "     SDQ_SDQ_Hyperactivity  SDQ_SDQ_Externalizing  fmri_pca_50  \\\n0                      7.0                    9.0    -0.324290   \n1                      3.0                    5.0    -1.979338   \n2                      5.0                    6.0     0.759340   \n3                      6.0                   10.0     0.383404   \n4                     10.0                   12.0    -0.581088   \n..                     ...                    ...          ...   \n299                    6.0                    7.0     1.779283   \n300                    9.0                   11.0    -0.496668   \n301                    3.0                    4.0    -1.422683   \n302                    5.0                   10.0     1.290901   \n303                    4.0                    4.0    -0.520944   \n\n     SDQ_SDQ_Difficulties_Total  fmri_pca_48  fmri_pca_31  fmri_pca_37  \\\n0                          12.0    -2.324203     1.942373    -1.688586   \n1                          16.0     3.631067     1.124477     0.380299   \n2                           7.0    -1.706108     1.724166    -0.376089   \n3                          15.0     1.082908     0.890923    -2.085292   \n4                          18.0     0.865579    -1.806361     1.162843   \n..                          ...          ...          ...          ...   \n299                        18.0    -0.912265    -0.761078    -0.543698   \n300                        16.0     2.589713    -1.110183    -0.712363   \n301                        11.0     0.148043     3.704947     1.921459   \n302                        21.0    -1.170213     3.771796     1.804700   \n303                         4.0     0.064288    -0.880193     0.328936   \n\n     fmri_pca_5  fmri_pca_35  fmri_pca_33  ...  fmri_pca_24  fmri_pca_23  \\\n0      0.930748    -1.173564     0.180032  ...     1.275498    -0.306033   \n1      2.667334    -4.309650    -1.263532  ...     3.491815    -1.864578   \n2     -2.053957     0.789639    -2.873811  ...     0.315485    -1.639236   \n3      0.741584     0.295368     0.601205  ...    -0.769030     0.028741   \n4     -2.280240     1.690596     0.055766  ...     1.480784    -0.838887   \n..          ...          ...          ...  ...          ...          ...   \n299    1.465643    -0.862118     1.494788  ...    -0.612311     0.887675   \n300    1.268605     7.740441     2.699661  ...     6.884819     2.536611   \n301    2.498292    -1.939094     0.587137  ...     1.781372     2.695057   \n302   -6.782507     0.371130    -0.162611  ...     0.782527    -0.035039   \n303   -1.561938     0.626112    -0.107155  ...    -5.348597     2.513491   \n\n     fmri_pca_42  fmri_pca_11  fmri_pca_32  fmri_pca_43  fmri_pca_29  \\\n0       1.716070     4.150425     0.379226    -0.773796     2.754719   \n1       0.953023     4.199631     1.192092     0.447701    -0.215396   \n2       0.413656    -3.036462     1.784396     1.916834     0.875269   \n3      -2.030191    -4.397754    -0.300261     0.928140    -1.604671   \n4      -0.719495    -0.571178    -2.855215     2.524235     1.205504   \n..           ...          ...          ...          ...          ...   \n299     2.123764     1.626029    -2.169787    -0.058980     0.829895   \n300     0.035010     1.863492     1.051392    -2.556971     2.006615   \n301    -1.528450     1.438116    -0.957751     1.887081     3.482524   \n302    -0.616927    -0.129434     2.974451    -0.136344    -2.643271   \n303    -2.123524    -0.123737     2.157519    -0.641724     0.844187   \n\n     fmri_pca_41  fmri_pca_12  fmri_pca_17  \n0      -0.926181    -1.461191    -1.520688  \n1      -2.004347     1.631035     1.977907  \n2      -1.200967    -1.393299     2.840884  \n3      -0.607864    -1.457293     0.699531  \n4      -0.436673     1.126602     0.598251  \n..           ...          ...          ...  \n299    -0.760154    -2.224182     0.036516  \n300    -2.112862    -4.859356    -0.304729  \n301     3.508512    -1.523458    -1.482218  \n302    -0.928147    -1.844048     0.866393  \n303     2.020262     1.722554     1.371893  \n\n[304 rows x 50 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SDQ_SDQ_Hyperactivity</th>\n      <th>SDQ_SDQ_Externalizing</th>\n      <th>fmri_pca_50</th>\n      <th>SDQ_SDQ_Difficulties_Total</th>\n      <th>fmri_pca_48</th>\n      <th>fmri_pca_31</th>\n      <th>fmri_pca_37</th>\n      <th>fmri_pca_5</th>\n      <th>fmri_pca_35</th>\n      <th>fmri_pca_33</th>\n      <th>...</th>\n      <th>fmri_pca_24</th>\n      <th>fmri_pca_23</th>\n      <th>fmri_pca_42</th>\n      <th>fmri_pca_11</th>\n      <th>fmri_pca_32</th>\n      <th>fmri_pca_43</th>\n      <th>fmri_pca_29</th>\n      <th>fmri_pca_41</th>\n      <th>fmri_pca_12</th>\n      <th>fmri_pca_17</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.0</td>\n      <td>9.0</td>\n      <td>-0.324290</td>\n      <td>12.0</td>\n      <td>-2.324203</td>\n      <td>1.942373</td>\n      <td>-1.688586</td>\n      <td>0.930748</td>\n      <td>-1.173564</td>\n      <td>0.180032</td>\n      <td>...</td>\n      <td>1.275498</td>\n      <td>-0.306033</td>\n      <td>1.716070</td>\n      <td>4.150425</td>\n      <td>0.379226</td>\n      <td>-0.773796</td>\n      <td>2.754719</td>\n      <td>-0.926181</td>\n      <td>-1.461191</td>\n      <td>-1.520688</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>-1.979338</td>\n      <td>16.0</td>\n      <td>3.631067</td>\n      <td>1.124477</td>\n      <td>0.380299</td>\n      <td>2.667334</td>\n      <td>-4.309650</td>\n      <td>-1.263532</td>\n      <td>...</td>\n      <td>3.491815</td>\n      <td>-1.864578</td>\n      <td>0.953023</td>\n      <td>4.199631</td>\n      <td>1.192092</td>\n      <td>0.447701</td>\n      <td>-0.215396</td>\n      <td>-2.004347</td>\n      <td>1.631035</td>\n      <td>1.977907</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>0.759340</td>\n      <td>7.0</td>\n      <td>-1.706108</td>\n      <td>1.724166</td>\n      <td>-0.376089</td>\n      <td>-2.053957</td>\n      <td>0.789639</td>\n      <td>-2.873811</td>\n      <td>...</td>\n      <td>0.315485</td>\n      <td>-1.639236</td>\n      <td>0.413656</td>\n      <td>-3.036462</td>\n      <td>1.784396</td>\n      <td>1.916834</td>\n      <td>0.875269</td>\n      <td>-1.200967</td>\n      <td>-1.393299</td>\n      <td>2.840884</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6.0</td>\n      <td>10.0</td>\n      <td>0.383404</td>\n      <td>15.0</td>\n      <td>1.082908</td>\n      <td>0.890923</td>\n      <td>-2.085292</td>\n      <td>0.741584</td>\n      <td>0.295368</td>\n      <td>0.601205</td>\n      <td>...</td>\n      <td>-0.769030</td>\n      <td>0.028741</td>\n      <td>-2.030191</td>\n      <td>-4.397754</td>\n      <td>-0.300261</td>\n      <td>0.928140</td>\n      <td>-1.604671</td>\n      <td>-0.607864</td>\n      <td>-1.457293</td>\n      <td>0.699531</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10.0</td>\n      <td>12.0</td>\n      <td>-0.581088</td>\n      <td>18.0</td>\n      <td>0.865579</td>\n      <td>-1.806361</td>\n      <td>1.162843</td>\n      <td>-2.280240</td>\n      <td>1.690596</td>\n      <td>0.055766</td>\n      <td>...</td>\n      <td>1.480784</td>\n      <td>-0.838887</td>\n      <td>-0.719495</td>\n      <td>-0.571178</td>\n      <td>-2.855215</td>\n      <td>2.524235</td>\n      <td>1.205504</td>\n      <td>-0.436673</td>\n      <td>1.126602</td>\n      <td>0.598251</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>1.779283</td>\n      <td>18.0</td>\n      <td>-0.912265</td>\n      <td>-0.761078</td>\n      <td>-0.543698</td>\n      <td>1.465643</td>\n      <td>-0.862118</td>\n      <td>1.494788</td>\n      <td>...</td>\n      <td>-0.612311</td>\n      <td>0.887675</td>\n      <td>2.123764</td>\n      <td>1.626029</td>\n      <td>-2.169787</td>\n      <td>-0.058980</td>\n      <td>0.829895</td>\n      <td>-0.760154</td>\n      <td>-2.224182</td>\n      <td>0.036516</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>9.0</td>\n      <td>11.0</td>\n      <td>-0.496668</td>\n      <td>16.0</td>\n      <td>2.589713</td>\n      <td>-1.110183</td>\n      <td>-0.712363</td>\n      <td>1.268605</td>\n      <td>7.740441</td>\n      <td>2.699661</td>\n      <td>...</td>\n      <td>6.884819</td>\n      <td>2.536611</td>\n      <td>0.035010</td>\n      <td>1.863492</td>\n      <td>1.051392</td>\n      <td>-2.556971</td>\n      <td>2.006615</td>\n      <td>-2.112862</td>\n      <td>-4.859356</td>\n      <td>-0.304729</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>-1.422683</td>\n      <td>11.0</td>\n      <td>0.148043</td>\n      <td>3.704947</td>\n      <td>1.921459</td>\n      <td>2.498292</td>\n      <td>-1.939094</td>\n      <td>0.587137</td>\n      <td>...</td>\n      <td>1.781372</td>\n      <td>2.695057</td>\n      <td>-1.528450</td>\n      <td>1.438116</td>\n      <td>-0.957751</td>\n      <td>1.887081</td>\n      <td>3.482524</td>\n      <td>3.508512</td>\n      <td>-1.523458</td>\n      <td>-1.482218</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>5.0</td>\n      <td>10.0</td>\n      <td>1.290901</td>\n      <td>21.0</td>\n      <td>-1.170213</td>\n      <td>3.771796</td>\n      <td>1.804700</td>\n      <td>-6.782507</td>\n      <td>0.371130</td>\n      <td>-0.162611</td>\n      <td>...</td>\n      <td>0.782527</td>\n      <td>-0.035039</td>\n      <td>-0.616927</td>\n      <td>-0.129434</td>\n      <td>2.974451</td>\n      <td>-0.136344</td>\n      <td>-2.643271</td>\n      <td>-0.928147</td>\n      <td>-1.844048</td>\n      <td>0.866393</td>\n    </tr>\n    <tr>\n      <th>303</th>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>-0.520944</td>\n      <td>4.0</td>\n      <td>0.064288</td>\n      <td>-0.880193</td>\n      <td>0.328936</td>\n      <td>-1.561938</td>\n      <td>0.626112</td>\n      <td>-0.107155</td>\n      <td>...</td>\n      <td>-5.348597</td>\n      <td>2.513491</td>\n      <td>-2.123524</td>\n      <td>-0.123737</td>\n      <td>2.157519</td>\n      <td>-0.641724</td>\n      <td>0.844187</td>\n      <td>2.020262</td>\n      <td>1.722554</td>\n      <td>1.371893</td>\n    </tr>\n  </tbody>\n</table>\n<p>304 rows × 50 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge everything on participant_id\n",
    "X_full = test_quant[['participant_id'] + quant_selected] \\\n",
    "    .merge(test_cat, on='participant_id') \\\n",
    "    .merge(test_func_pca, on='participant_id')\n",
    "\n",
    "# Final X for model training (top_features_final from random forests done on training set)\n",
    "X_test_selected = X_full[top_features_final]\n",
    "X_test_selected"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T03:35:28.557219Z",
     "start_time": "2025-04-21T03:35:28.116486Z"
    }
   },
   "id": "9154607279190361",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "    participant_id  ADHD_Outcome  Sex_F\n0     Cfwaf5FX7jWK             1      0\n1     vhGrzmvA3Hjq             1      1\n2     ULliyEXjy4OV             1      0\n3     LZfeAb1xMtql             1      0\n4     EnFOUv0YK1RG             1      0\n..             ...           ...    ...\n299   UadZfjdEg7eG             1      0\n300   IUEHiLmQAqCi             1      1\n301   cRySmCadYFRO             1      0\n302   E3MvDUtJadc5             1      0\n303   dQJXfyRazknD             0      0\n\n[304 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>participant_id</th>\n      <th>ADHD_Outcome</th>\n      <th>Sex_F</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cfwaf5FX7jWK</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>vhGrzmvA3Hjq</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ULliyEXjy4OV</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LZfeAb1xMtql</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>EnFOUv0YK1RG</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>UadZfjdEg7eG</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>IUEHiLmQAqCi</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>cRySmCadYFRO</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>E3MvDUtJadc5</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>303</th>\n      <td>dQJXfyRazknD</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>304 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize test data\n",
    "X_test_scaled = scaler.transform(X_test_selected)\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "\n",
    "# Load into DataLoader\n",
    "test_loader_final = DataLoader(X_test_tensor, batch_size=32)\n",
    "\n",
    "# Set model to eval mode and load best weights\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "\n",
    "adhd_preds, sex_preds = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb in test_loader_final:\n",
    "        adhd_out, sex_out = model(xb)\n",
    "        adhd_preds.append(adhd_out)\n",
    "        sex_preds.append(sex_out)\n",
    "\n",
    "# Concatenate and threshold at 0.5\n",
    "adhd_preds = torch.cat(adhd_preds).squeeze().numpy()\n",
    "sex_preds = torch.cat(sex_preds).squeeze().numpy()\n",
    "\n",
    "adhd_pred_labels = (adhd_preds > 0.5).astype(int)\n",
    "sex_pred_labels = (sex_preds > 0.5).astype(int)\n",
    "\n",
    "# Create test_soln submission DataFrame\n",
    "test_soln = pd.DataFrame({\n",
    "    'participant_id': X_full['participant_id'],  # or test_func['participant_id']\n",
    "    'ADHD_Outcome': adhd_pred_labels,\n",
    "    'Sex_F': sex_pred_labels\n",
    "})\n",
    "\n",
    "test_soln.to_csv(\"submission.csv\", index=False)\n",
    "test_soln"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T03:37:14.657735Z",
     "start_time": "2025-04-21T03:37:14.560300Z"
    }
   },
   "id": "a9da8b679a035942",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5d462c8c46aa2a6e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
