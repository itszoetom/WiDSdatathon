{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14649cef",
   "metadata": {},
   "source": [
    "### Load in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a73ebe7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T02:51:38.363713Z",
     "start_time": "2025-04-23T02:51:32.040821Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Use read_excel and use participant_id as the index\n",
    "train_cat = pd.read_excel(\"../../widsdatathon2025/TRAIN_NEW/TRAIN_CATEGORICAL_METADATA_new.xlsx\")\n",
    "train_func = pd.read_csv(\"../../widsdatathon2025/TRAIN_NEW/\"\n",
    "                         \"TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv\")\n",
    "train_quant = pd.read_excel(\"../../widsdatathon2025/TRAIN_NEW/TRAIN_QUANTITATIVE_METADATA_new.xlsx\")\n",
    "train_soln = pd.read_excel(\"../../widsdatathon2025/TRAIN_NEW/TRAINING_SOLUTIONS.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d5a6a6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T02:51:43.025487Z",
     "start_time": "2025-04-23T02:51:43.011841Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set index for merging\n",
    "train_cat.set_index(\"participant_id\", inplace=True)\n",
    "train_quant.set_index(\"participant_id\", inplace=True)\n",
    "train_func.set_index(\"participant_id\", inplace=True)\n",
    "train_soln.set_index(\"participant_id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                Basic_Demos_Enroll_Year  Basic_Demos_Study_Site  \\\nparticipant_id                                                    \n00aIpNTbG5uh                       2019                       4   \n00fV0OyyoLfw                       2017                       1   \n04X1eiS79T4B                       2017                       1   \n05ocQutkURd6                       2018                       1   \n06YUNBA9ZRLq                       2018                       1   \n\n                PreInt_Demos_Fam_Child_Ethnicity  PreInt_Demos_Fam_Child_Race  \\\nparticipant_id                                                                  \n00aIpNTbG5uh                                 1.0                          0.0   \n00fV0OyyoLfw                                 0.0                          9.0   \n04X1eiS79T4B                                 1.0                          2.0   \n05ocQutkURd6                                 3.0                          8.0   \n06YUNBA9ZRLq                                 0.0                          1.0   \n\n                MRI_Track_Scan_Location  Barratt_Barratt_P1_Edu  \\\nparticipant_id                                                    \n00aIpNTbG5uh                        3.0                    21.0   \n00fV0OyyoLfw                        2.0                    21.0   \n04X1eiS79T4B                        2.0                     9.0   \n05ocQutkURd6                        2.0                    18.0   \n06YUNBA9ZRLq                        2.0                    12.0   \n\n                Barratt_Barratt_P1_Occ  Barratt_Barratt_P2_Edu  \\\nparticipant_id                                                   \n00aIpNTbG5uh                      45.0                     NaN   \n00fV0OyyoLfw                       0.0                    21.0   \n04X1eiS79T4B                       0.0                     NaN   \n05ocQutkURd6                      10.0                    18.0   \n06YUNBA9ZRLq                       0.0                     NaN   \n\n                Barratt_Barratt_P2_Occ  \nparticipant_id                          \n00aIpNTbG5uh                       NaN  \n00fV0OyyoLfw                      45.0  \n04X1eiS79T4B                       NaN  \n05ocQutkURd6                       0.0  \n06YUNBA9ZRLq                       NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Basic_Demos_Enroll_Year</th>\n      <th>Basic_Demos_Study_Site</th>\n      <th>PreInt_Demos_Fam_Child_Ethnicity</th>\n      <th>PreInt_Demos_Fam_Child_Race</th>\n      <th>MRI_Track_Scan_Location</th>\n      <th>Barratt_Barratt_P1_Edu</th>\n      <th>Barratt_Barratt_P1_Occ</th>\n      <th>Barratt_Barratt_P2_Edu</th>\n      <th>Barratt_Barratt_P2_Occ</th>\n    </tr>\n    <tr>\n      <th>participant_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>00aIpNTbG5uh</th>\n      <td>2019</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>21.0</td>\n      <td>45.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>00fV0OyyoLfw</th>\n      <td>2017</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>9.0</td>\n      <td>2.0</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>21.0</td>\n      <td>45.0</td>\n    </tr>\n    <tr>\n      <th>04X1eiS79T4B</th>\n      <td>2017</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>05ocQutkURd6</th>\n      <td>2018</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>8.0</td>\n      <td>2.0</td>\n      <td>18.0</td>\n      <td>10.0</td>\n      <td>18.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>06YUNBA9ZRLq</th>\n      <td>2018</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cat.head()\n",
    "# train_func.head()\n",
    "# train_quant.head()\n",
    "# train_soln.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T02:51:45.119064Z",
     "start_time": "2025-04-23T02:51:44.966346Z"
    }
   },
   "id": "fd5a7b91f88e16c7",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "406df64c16f6625a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## PCA for the functional connectome matrix to reduce dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac7849a1151a7af0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T02:52:20.814749Z",
     "start_time": "2025-04-23T02:52:08.324829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                fmri_pca_1  fmri_pca_2  fmri_pca_3  fmri_pca_4  fmri_pca_5  \\\nparticipant_id                                                               \n70z8Q2xdTXM3      6.322800   -0.365680   -4.918161   -3.823232   -5.706925   \nWHWymJu6zNZi      5.468294   -3.985252    1.542399    0.104719   -0.529037   \n4PAQp1M6EyAo      0.447190    0.733000    3.051332    1.763902    1.932819   \nobEacy4Of68I     -9.149799   -2.044626    0.519359   -2.703924   -4.444126   \ns7WzzDcmDOhF      0.812814   -1.933265    1.834524    0.383159   -0.512337   \n\n                fmri_pca_6  fmri_pca_7  fmri_pca_8  fmri_pca_9  fmri_pca_10  \\\nparticipant_id                                                                \n70z8Q2xdTXM3     -0.875168    1.567537   -1.347493   -1.717403     1.626701   \nWHWymJu6zNZi     -2.951977    0.786366    0.794952   -2.772055    -2.408920   \n4PAQp1M6EyAo      6.451154   -3.356874    1.946051   -1.165636    -2.876858   \nobEacy4Of68I      2.916930    1.036396    0.080340   -0.148185     0.384233   \ns7WzzDcmDOhF      2.972219    3.151062    3.419848    0.283679    -2.997809   \n\n                ...  fmri_pca_41  fmri_pca_42  fmri_pca_43  fmri_pca_44  \\\nparticipant_id  ...                                                       \n70z8Q2xdTXM3    ...     0.805249    -0.708449     0.249169     0.276250   \nWHWymJu6zNZi    ...     1.042380     0.614140    -0.807448     0.320061   \n4PAQp1M6EyAo    ...    -2.169494    -0.191489     2.517191     0.890518   \nobEacy4Of68I    ...    -0.135033    -1.807585     0.420512    -0.754358   \ns7WzzDcmDOhF    ...     2.412607    -2.108522    -2.713573    -0.937563   \n\n                fmri_pca_45  fmri_pca_46  fmri_pca_47  fmri_pca_48  \\\nparticipant_id                                                       \n70z8Q2xdTXM3       1.572329    -2.987128    -3.439043     0.645766   \nWHWymJu6zNZi      -1.816425    -0.341490     0.986329    -0.596418   \n4PAQp1M6EyAo      -0.377794    -1.691477    -0.282250    -1.066496   \nobEacy4Of68I      -0.740293    -0.620120    -0.357497     1.086135   \ns7WzzDcmDOhF      -0.430740     0.346970     0.454387    -1.873252   \n\n                fmri_pca_49  fmri_pca_50  \nparticipant_id                            \n70z8Q2xdTXM3      -0.433957     0.182288  \nWHWymJu6zNZi       1.178288    -0.786373  \n4PAQp1M6EyAo       2.499244    -1.190171  \nobEacy4Of68I       0.242517     1.022253  \ns7WzzDcmDOhF       1.095752     0.388524  \n\n[5 rows x 50 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fmri_pca_1</th>\n      <th>fmri_pca_2</th>\n      <th>fmri_pca_3</th>\n      <th>fmri_pca_4</th>\n      <th>fmri_pca_5</th>\n      <th>fmri_pca_6</th>\n      <th>fmri_pca_7</th>\n      <th>fmri_pca_8</th>\n      <th>fmri_pca_9</th>\n      <th>fmri_pca_10</th>\n      <th>...</th>\n      <th>fmri_pca_41</th>\n      <th>fmri_pca_42</th>\n      <th>fmri_pca_43</th>\n      <th>fmri_pca_44</th>\n      <th>fmri_pca_45</th>\n      <th>fmri_pca_46</th>\n      <th>fmri_pca_47</th>\n      <th>fmri_pca_48</th>\n      <th>fmri_pca_49</th>\n      <th>fmri_pca_50</th>\n    </tr>\n    <tr>\n      <th>participant_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>70z8Q2xdTXM3</th>\n      <td>6.322800</td>\n      <td>-0.365680</td>\n      <td>-4.918161</td>\n      <td>-3.823232</td>\n      <td>-5.706925</td>\n      <td>-0.875168</td>\n      <td>1.567537</td>\n      <td>-1.347493</td>\n      <td>-1.717403</td>\n      <td>1.626701</td>\n      <td>...</td>\n      <td>0.805249</td>\n      <td>-0.708449</td>\n      <td>0.249169</td>\n      <td>0.276250</td>\n      <td>1.572329</td>\n      <td>-2.987128</td>\n      <td>-3.439043</td>\n      <td>0.645766</td>\n      <td>-0.433957</td>\n      <td>0.182288</td>\n    </tr>\n    <tr>\n      <th>WHWymJu6zNZi</th>\n      <td>5.468294</td>\n      <td>-3.985252</td>\n      <td>1.542399</td>\n      <td>0.104719</td>\n      <td>-0.529037</td>\n      <td>-2.951977</td>\n      <td>0.786366</td>\n      <td>0.794952</td>\n      <td>-2.772055</td>\n      <td>-2.408920</td>\n      <td>...</td>\n      <td>1.042380</td>\n      <td>0.614140</td>\n      <td>-0.807448</td>\n      <td>0.320061</td>\n      <td>-1.816425</td>\n      <td>-0.341490</td>\n      <td>0.986329</td>\n      <td>-0.596418</td>\n      <td>1.178288</td>\n      <td>-0.786373</td>\n    </tr>\n    <tr>\n      <th>4PAQp1M6EyAo</th>\n      <td>0.447190</td>\n      <td>0.733000</td>\n      <td>3.051332</td>\n      <td>1.763902</td>\n      <td>1.932819</td>\n      <td>6.451154</td>\n      <td>-3.356874</td>\n      <td>1.946051</td>\n      <td>-1.165636</td>\n      <td>-2.876858</td>\n      <td>...</td>\n      <td>-2.169494</td>\n      <td>-0.191489</td>\n      <td>2.517191</td>\n      <td>0.890518</td>\n      <td>-0.377794</td>\n      <td>-1.691477</td>\n      <td>-0.282250</td>\n      <td>-1.066496</td>\n      <td>2.499244</td>\n      <td>-1.190171</td>\n    </tr>\n    <tr>\n      <th>obEacy4Of68I</th>\n      <td>-9.149799</td>\n      <td>-2.044626</td>\n      <td>0.519359</td>\n      <td>-2.703924</td>\n      <td>-4.444126</td>\n      <td>2.916930</td>\n      <td>1.036396</td>\n      <td>0.080340</td>\n      <td>-0.148185</td>\n      <td>0.384233</td>\n      <td>...</td>\n      <td>-0.135033</td>\n      <td>-1.807585</td>\n      <td>0.420512</td>\n      <td>-0.754358</td>\n      <td>-0.740293</td>\n      <td>-0.620120</td>\n      <td>-0.357497</td>\n      <td>1.086135</td>\n      <td>0.242517</td>\n      <td>1.022253</td>\n    </tr>\n    <tr>\n      <th>s7WzzDcmDOhF</th>\n      <td>0.812814</td>\n      <td>-1.933265</td>\n      <td>1.834524</td>\n      <td>0.383159</td>\n      <td>-0.512337</td>\n      <td>2.972219</td>\n      <td>3.151062</td>\n      <td>3.419848</td>\n      <td>0.283679</td>\n      <td>-2.997809</td>\n      <td>...</td>\n      <td>2.412607</td>\n      <td>-2.108522</td>\n      <td>-2.713573</td>\n      <td>-0.937563</td>\n      <td>-0.430740</td>\n      <td>0.346970</td>\n      <td>0.454387</td>\n      <td>-1.873252</td>\n      <td>1.095752</td>\n      <td>0.388524</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 50 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Select only fMRI columns\n",
    "fmri_data = train_func.drop(columns=['participant_id'], errors='ignore')\n",
    "\n",
    "# Apply PCA to reduce to top N components (e.g. 50)\n",
    "pca = PCA(n_components=50)\n",
    "fmri_pca = pca.fit_transform(fmri_data)\n",
    "\n",
    "train_func_pca = pd.DataFrame(fmri_pca, index=train_func.index,\n",
    "                           columns=[f'fmri_pca_{i}' for i in range(1, 51)])\n",
    "train_func_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a5a24f4a19a842",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Interpolate missing values with mean for quant and cat dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea3161a9934e682c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T02:52:25.330170Z",
     "start_time": "2025-04-23T02:52:24.454288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in train_quant:\n",
      " EHQ_EHQ_Total                  13\n",
      "ColorVision_CV_Score           23\n",
      "APQ_P_APQ_P_CP                 12\n",
      "APQ_P_APQ_P_ID                 12\n",
      "APQ_P_APQ_P_INV                12\n",
      "APQ_P_APQ_P_OPD                12\n",
      "APQ_P_APQ_P_PM                 12\n",
      "APQ_P_APQ_P_PP                 12\n",
      "SDQ_SDQ_Conduct_Problems        9\n",
      "SDQ_SDQ_Difficulties_Total      9\n",
      "SDQ_SDQ_Emotional_Problems      9\n",
      "SDQ_SDQ_Externalizing           9\n",
      "SDQ_SDQ_Generating_Impact       9\n",
      "SDQ_SDQ_Hyperactivity           9\n",
      "SDQ_SDQ_Internalizing           9\n",
      "SDQ_SDQ_Peer_Problems           9\n",
      "SDQ_SDQ_Prosocial               9\n",
      "MRI_Track_Age_at_Scan         360\n",
      "dtype: int64\n",
      "Missing values in train_cat:\n",
      " PreInt_Demos_Fam_Child_Ethnicity     43\n",
      "PreInt_Demos_Fam_Child_Race          54\n",
      "MRI_Track_Scan_Location               3\n",
      "Barratt_Barratt_P1_Edu               15\n",
      "Barratt_Barratt_P1_Occ               31\n",
      "Barratt_Barratt_P2_Edu              198\n",
      "Barratt_Barratt_P2_Occ              222\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Check missing values *before* merging\n",
    "missing = train_quant.isnull().sum()\n",
    "missing_cat = train_cat.isnull().sum()\n",
    "print(\"Missing values in train_quant:\\n\", missing[missing > 0])\n",
    "print(\"Missing values in train_cat:\\n\", missing_cat[missing_cat > 0])\n",
    "\n",
    "# Define columns with small gaps to impute\n",
    "small_gap_cols = [\n",
    "    'EHQ_EHQ_Total', 'ColorVision_CV_Score', 'APQ_P_APQ_P_CP', 'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV',\n",
    "    'APQ_P_APQ_P_OPD', 'APQ_P_APQ_P_PM', 'APQ_P_APQ_P_PP', 'SDQ_SDQ_Conduct_Problems', \n",
    "    'SDQ_SDQ_Difficulties_Total', 'SDQ_SDQ_Emotional_Problems', 'SDQ_SDQ_Externalizing',\n",
    "    'SDQ_SDQ_Generating_Impact', 'SDQ_SDQ_Hyperactivity', 'SDQ_SDQ_Internalizing', \n",
    "    'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial', 'PreInt_Demos_Fam_Child_Ethnicity',\n",
    "    'PreInt_Demos_Fam_Child_Race', 'MRI_Track_Scan_Location']\n",
    "\n",
    "small_gap_cols_cat = ['Barratt_Barratt_P1_Edu', 'Barratt_Barratt_P1_Occ']\n",
    "\n",
    "# Fill small gaps using column means\n",
    "for col in small_gap_cols:\n",
    "    if col in train_quant.columns:\n",
    "        train_quant[col] = train_quant[col].fillna(train_quant[col].mean())\n",
    "for col in small_gap_cols_cat:\n",
    "    if col in train_cat.columns:\n",
    "        train_cat[col] = train_cat[col].fillna(train_cat[col].mean())\n",
    "\n",
    "# drop rows where age is missing to train\n",
    "age_train = train_quant.dropna(subset=['MRI_Track_Age_at_Scan'])\n",
    "X = age_train.drop(columns=['MRI_Track_Age_at_Scan'])\n",
    "y = age_train['MRI_Track_Age_at_Scan']\n",
    "\n",
    "# maybe use SimpleImputer to handle small missingness in X\n",
    "X_imputed = SimpleImputer(strategy='mean').fit_transform(X)\n",
    "\n",
    "# train regressor\n",
    "reg = LinearRegression().fit(X_imputed, y)\n",
    "\n",
    "# now predict missing ages\n",
    "missing_age_rows = train_quant['MRI_Track_Age_at_Scan'].isna()\n",
    "X_missing = train_quant.loc[missing_age_rows].drop(columns=['MRI_Track_Age_at_Scan'])\n",
    "X_missing_imputed = SimpleImputer(strategy='mean').fit_transform(X_missing)\n",
    "\n",
    "# predict and fill\n",
    "train_quant.loc[missing_age_rows, 'MRI_Track_Age_at_Scan'] = reg.predict(X_missing_imputed)\n",
    "\n",
    "train_cat.drop(columns=['Barratt_Barratt_P2_Occ', 'Barratt_Barratt_P2_Edu'], \n",
    "              inplace=True) # Dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2138a83a91362272",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T02:52:29.940097Z",
     "start_time": "2025-04-23T02:52:29.916240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in train_quant:\n",
      " Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Check missing values *before* merging\n",
    "missing = train_quant.isnull().sum()\n",
    "print(\"Missing values in train_quant:\\n\", missing[missing > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "268e809ef085e969",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T02:52:33.645325Z",
     "start_time": "2025-04-23T02:52:33.598052Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                EHQ_EHQ_Total  ColorVision_CV_Score  APQ_P_APQ_P_CP  \\\nparticipant_id                                                        \n00aIpNTbG5uh           100.00                  13.0             3.0   \n00fV0OyyoLfw            92.27                  14.0             3.0   \n04X1eiS79T4B            86.67                  14.0             3.0   \n05ocQutkURd6            93.34                  14.0             3.0   \n06YUNBA9ZRLq             0.00                  14.0             8.0   \n\n                APQ_P_APQ_P_ID  APQ_P_APQ_P_INV  APQ_P_APQ_P_OPD  \\\nparticipant_id                                                     \n00aIpNTbG5uh              15.0             44.0             14.0   \n00fV0OyyoLfw              12.0             35.0             25.0   \n04X1eiS79T4B              21.0             37.0             18.0   \n05ocQutkURd6              11.0             42.0             15.0   \n06YUNBA9ZRLq              12.0             35.0             22.0   \n\n                APQ_P_APQ_P_PM  APQ_P_APQ_P_PP  SDQ_SDQ_Conduct_Problems  \\\nparticipant_id                                                             \n00aIpNTbG5uh              20.0            27.0                       3.0   \n00fV0OyyoLfw              28.0            30.0                       5.0   \n04X1eiS79T4B              26.0            28.0                       3.0   \n05ocQutkURd6              20.0            28.0                       0.0   \n06YUNBA9ZRLq              12.0            24.0                       6.0   \n\n                SDQ_SDQ_Difficulties_Total  ...  fmri_pca_41  fmri_pca_42  \\\nparticipant_id                              ...                             \n00aIpNTbG5uh                          17.0  ...     0.178457    -1.058854   \n00fV0OyyoLfw                          20.0  ...    -0.691156    -0.259812   \n04X1eiS79T4B                          24.0  ...     3.421913    -2.837251   \n05ocQutkURd6                           5.0  ...     1.624708     0.220991   \n06YUNBA9ZRLq                          23.0  ...     2.079449     1.469297   \n\n                fmri_pca_43  fmri_pca_44  fmri_pca_45  fmri_pca_46  \\\nparticipant_id                                                       \n00aIpNTbG5uh      -1.048715    -0.469334    -0.086935    -0.369650   \n00fV0OyyoLfw       0.293702    -0.859555     0.222115     1.175482   \n04X1eiS79T4B      -1.438680     0.240602    -2.693957    -0.729080   \n05ocQutkURd6       2.707044    -1.292513    -3.473682    -2.696214   \n06YUNBA9ZRLq       0.378476    -0.005113    -2.057296     1.791186   \n\n                fmri_pca_47  fmri_pca_48  fmri_pca_49  fmri_pca_50  \nparticipant_id                                                      \n00aIpNTbG5uh       0.546880    -1.148994    -3.277996    -1.433213  \n00fV0OyyoLfw      -2.890521     0.459076    -0.618329    -1.566080  \n04X1eiS79T4B       0.634930     2.377795     0.206991    -1.956194  \n05ocQutkURd6       1.372668     0.741779    -0.760894    -1.424114  \n06YUNBA9ZRLq      -1.085582     1.310953    -0.982533     0.365150  \n\n[5 rows x 75 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EHQ_EHQ_Total</th>\n      <th>ColorVision_CV_Score</th>\n      <th>APQ_P_APQ_P_CP</th>\n      <th>APQ_P_APQ_P_ID</th>\n      <th>APQ_P_APQ_P_INV</th>\n      <th>APQ_P_APQ_P_OPD</th>\n      <th>APQ_P_APQ_P_PM</th>\n      <th>APQ_P_APQ_P_PP</th>\n      <th>SDQ_SDQ_Conduct_Problems</th>\n      <th>SDQ_SDQ_Difficulties_Total</th>\n      <th>...</th>\n      <th>fmri_pca_41</th>\n      <th>fmri_pca_42</th>\n      <th>fmri_pca_43</th>\n      <th>fmri_pca_44</th>\n      <th>fmri_pca_45</th>\n      <th>fmri_pca_46</th>\n      <th>fmri_pca_47</th>\n      <th>fmri_pca_48</th>\n      <th>fmri_pca_49</th>\n      <th>fmri_pca_50</th>\n    </tr>\n    <tr>\n      <th>participant_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>00aIpNTbG5uh</th>\n      <td>100.00</td>\n      <td>13.0</td>\n      <td>3.0</td>\n      <td>15.0</td>\n      <td>44.0</td>\n      <td>14.0</td>\n      <td>20.0</td>\n      <td>27.0</td>\n      <td>3.0</td>\n      <td>17.0</td>\n      <td>...</td>\n      <td>0.178457</td>\n      <td>-1.058854</td>\n      <td>-1.048715</td>\n      <td>-0.469334</td>\n      <td>-0.086935</td>\n      <td>-0.369650</td>\n      <td>0.546880</td>\n      <td>-1.148994</td>\n      <td>-3.277996</td>\n      <td>-1.433213</td>\n    </tr>\n    <tr>\n      <th>00fV0OyyoLfw</th>\n      <td>92.27</td>\n      <td>14.0</td>\n      <td>3.0</td>\n      <td>12.0</td>\n      <td>35.0</td>\n      <td>25.0</td>\n      <td>28.0</td>\n      <td>30.0</td>\n      <td>5.0</td>\n      <td>20.0</td>\n      <td>...</td>\n      <td>-0.691156</td>\n      <td>-0.259812</td>\n      <td>0.293702</td>\n      <td>-0.859555</td>\n      <td>0.222115</td>\n      <td>1.175482</td>\n      <td>-2.890521</td>\n      <td>0.459076</td>\n      <td>-0.618329</td>\n      <td>-1.566080</td>\n    </tr>\n    <tr>\n      <th>04X1eiS79T4B</th>\n      <td>86.67</td>\n      <td>14.0</td>\n      <td>3.0</td>\n      <td>21.0</td>\n      <td>37.0</td>\n      <td>18.0</td>\n      <td>26.0</td>\n      <td>28.0</td>\n      <td>3.0</td>\n      <td>24.0</td>\n      <td>...</td>\n      <td>3.421913</td>\n      <td>-2.837251</td>\n      <td>-1.438680</td>\n      <td>0.240602</td>\n      <td>-2.693957</td>\n      <td>-0.729080</td>\n      <td>0.634930</td>\n      <td>2.377795</td>\n      <td>0.206991</td>\n      <td>-1.956194</td>\n    </tr>\n    <tr>\n      <th>05ocQutkURd6</th>\n      <td>93.34</td>\n      <td>14.0</td>\n      <td>3.0</td>\n      <td>11.0</td>\n      <td>42.0</td>\n      <td>15.0</td>\n      <td>20.0</td>\n      <td>28.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>1.624708</td>\n      <td>0.220991</td>\n      <td>2.707044</td>\n      <td>-1.292513</td>\n      <td>-3.473682</td>\n      <td>-2.696214</td>\n      <td>1.372668</td>\n      <td>0.741779</td>\n      <td>-0.760894</td>\n      <td>-1.424114</td>\n    </tr>\n    <tr>\n      <th>06YUNBA9ZRLq</th>\n      <td>0.00</td>\n      <td>14.0</td>\n      <td>8.0</td>\n      <td>12.0</td>\n      <td>35.0</td>\n      <td>22.0</td>\n      <td>12.0</td>\n      <td>24.0</td>\n      <td>6.0</td>\n      <td>23.0</td>\n      <td>...</td>\n      <td>2.079449</td>\n      <td>1.469297</td>\n      <td>0.378476</td>\n      <td>-0.005113</td>\n      <td>-2.057296</td>\n      <td>1.791186</td>\n      <td>-1.085582</td>\n      <td>1.310953</td>\n      <td>-0.982533</td>\n      <td>0.365150</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 75 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure participant_id is a column, not the index\n",
    "train_quant = train_quant.reset_index()\n",
    "train_cat = train_cat.reset_index()\n",
    "train_soln = train_soln.reset_index()\n",
    "\n",
    "# Merge everything on participant_id\n",
    "X_full = train_quant.merge(train_cat, on='participant_id').merge(train_func_pca, on='participant_id')\n",
    "\n",
    "# Target labels\n",
    "y = train_soln[['participant_id', 'ADHD_Outcome', 'Sex_F']]\n",
    "\n",
    "# Align rows across X and y\n",
    "X_full = X_full.merge(y, on='participant_id')\n",
    "y = X_full[['ADHD_Outcome', 'Sex_F']]\n",
    "X_full = X_full.drop(columns=['ADHD_Outcome', 'Sex_F'])\n",
    "X_full.set_index(\"participant_id\", inplace=True)\n",
    "X_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3597474bf27bb8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T03:02:27.010070Z",
     "start_time": "2025-04-23T03:02:26.988528Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-2.8209,  0.2776, -0.6192,  ...,  1.4297, -1.2718,  0.9630],\n        [ 0.2795,  0.2776,  0.1365,  ...,  0.3559, -0.7471, -1.3930],\n        [-1.0685,  0.2776, -0.6192,  ...,  0.4917, -0.5680, -0.1444],\n        ...,\n        [ 0.8186,  0.2776, -0.6192,  ..., -0.0194, -1.6136, -2.0732],\n        [ 0.8186,  0.2776, -0.6192,  ...,  0.0346, -0.2227,  0.9131],\n        [ 0.1447,  0.2776, -0.6192,  ..., -1.0130, -0.5518,  0.2717]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_full)\n",
    "\n",
    "# Convert to tensors\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float32)\n",
    "\n",
    "# Stratified train/test split\n",
    "stratify_labels = y['ADHD_Outcome'].astype(str) + y['Sex_F'].astype(str)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tensor, y_tensor, test_size=0.2, random_state=42, stratify=stratify_labels)\n",
    "\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "test_ds = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=32)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class DualOutputNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.head_adhd = nn.Linear(128, 1)\n",
    "        self.head_sex = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shared_out = self.shared(x)\n",
    "        adhd_logits = self.head_adhd(shared_out)\n",
    "        sex_logits = self.head_sex(shared_out)\n",
    "        return adhd_logits, sex_logits\n",
    "\n",
    "class WeightedBCELoss(nn.Module):\n",
    "    def __init__(self, weight_female_adhd=2.0):\n",
    "        super(WeightedBCELoss, self).__init__()\n",
    "        self.weight_female_adhd = weight_female_adhd\n",
    "        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "    def forward(self, predictions, targets, sex):\n",
    "        bce_loss = self.bce(predictions, targets)\n",
    "\n",
    "        # Initialize weights to 1\n",
    "        weight = torch.ones_like(bce_loss)\n",
    "\n",
    "        # Apply weight for female ADHD cases (ADHD = 1 and sex = female)\n",
    "        weight[(targets == 1) & (sex == 1)] = self.weight_female_adhd\n",
    "\n",
    "        # Apply weights\n",
    "        weighted_loss = weight * bce_loss\n",
    "        return weighted_loss.mean()\n",
    "\n",
    "# Initialize model and loss function\n",
    "model = DualOutputNN(X_full.shape[1])\n",
    "weighted_criterion = WeightedBCELoss(weight_female_adhd=2)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n",
    "\n",
    "# Training loop with early stopping\n",
    "best_val_loss = np.inf\n",
    "patience = 5\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for xb, yb in train_loader:\n",
    "        adhd_pred, sex_pred = model(xb)\n",
    "        # Extract ADHD and Sex labels\n",
    "        adhd_labels = yb[:, 0]\n",
    "        sex_labels = yb[:, 1]\n",
    "        \n",
    "        # Compute weighted loss for both ADHD and Sex\n",
    "        loss_adhd = weighted_criterion(adhd_pred.squeeze(), adhd_labels, sex_labels)\n",
    "        loss_sex = weighted_criterion(sex_pred.squeeze(), sex_labels, sex_labels)\n",
    "        \n",
    "        # Total loss\n",
    "        loss = loss_adhd + loss_sex\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            adhd_pred, sex_pred = model(xb)\n",
    "            loss_adhd = weighted_criterion(adhd_pred.squeeze(), yb[:, 0], yb[:, 1])\n",
    "            loss_sex = weighted_criterion(sex_pred.squeeze(), yb[:, 1], yb[:, 1])\n",
    "            val_loss = loss_adhd + loss_sex\n",
    "            val_losses.append(val_loss.item())\n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {running_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_model = model.state_dict()\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# Evaluation\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "\n",
    "all_preds, all_true = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        adhd_logits, sex_logits = model(xb)\n",
    "        adhd_probs = torch.sigmoid(adhd_logits)\n",
    "        sex_probs = torch.sigmoid(sex_logits)\n",
    "        preds = torch.cat([adhd_probs, sex_probs], dim=1)\n",
    "        all_preds.append(preds)\n",
    "        all_true.append(yb)\n",
    "\n",
    "all_preds = torch.cat(all_preds).numpy()\n",
    "all_true = torch.cat(all_true).numpy()\n",
    "\n",
    "# Binary prediction\n",
    "adhd_pred_labels = (all_preds[:, 0] > 0.5).astype(int)\n",
    "sex_pred_labels = (all_preds[:, 1] > 0.5).astype(int)\n",
    "\n",
    "# True labels\n",
    "all_true_adhd = all_true[:, 0].astype(int)\n",
    "all_true_sex = all_true[:, 1].astype(int)\n",
    "\n",
    "# Compute weighted F1 Score with 2x weight for Female ADHD cases\n",
    "def weighted_f1(y_true, y_pred, weight_column):\n",
    "    # Assign a weight of 2x for Female ADHD cases\n",
    "    weight = np.ones_like(y_true)\n",
    "    weight[(y_true == 1) & (weight_column == 1)] = 3  # Apply 2x weight for Female ADHD\n",
    "    \n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', sample_weight=weight)\n",
    "    return f1\n",
    "\n",
    "f1_adhd = weighted_f1(all_true_adhd, adhd_pred_labels, all_true_sex)\n",
    "f1_sex = weighted_f1(all_true_sex, sex_pred_labels, all_true_sex)\n",
    "\n",
    "print(f\"\\nADHD Weighted F1 Score: {f1_adhd:.4f}\")\n",
    "print(f\"Sex Weighted F1 Score: {f1_sex:.4f}\")\n",
    "\n",
    "# Metrics for ADHD\n",
    "def print_metrics(y_true, y_pred, name):\n",
    "    print(f\"\\n {name} Metrics:\")\n",
    "    print(f\"Accuracy:  {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"F1 Score:  {f1_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Recall:    {recall_score(y_true, y_pred):.4f}\")\n",
    "\n",
    "print_metrics(all_true_adhd, adhd_pred_labels, \"ADHD\")\n",
    "print_metrics(all_true_sex, sex_pred_labels, \"Sex\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4aef922b30b6a1bf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing and Submission"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1226e02566ee980"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Use read_excel and use participant_id as the index\n",
    "test_cat = pd.read_excel(\"../../widsdatathon2025/TEST/TEST_CATEGORICAL.xlsx\")\n",
    "test_func = pd.read_csv(\"../../widsdatathon2025/TEST/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv\")\n",
    "test_quant = pd.read_excel(\"../../widsdatathon2025/TEST/TEST_QUANTITATIVE_METADATA.xlsx\")\n",
    "solutions_path = \"../../widsdatathon2025/TEST/TEST_SOLUTIONS.xlsx\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T03:17:42.990197Z",
     "start_time": "2025-04-21T03:17:40.874661Z"
    }
   },
   "id": "e6f2115a91900652",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  participant_id  0throw_1thcolumn  0throw_2thcolumn  0throw_3thcolumn  \\\n0   Cfwaf5FX7jWK          0.548480          0.713607          0.557319   \n1   vhGrzmvA3Hjq          0.427740          0.363022          0.402862   \n2   ULliyEXjy4OV          0.139572          0.390106         -0.087041   \n3   LZfeAb1xMtql          0.133561          0.778326          0.416355   \n4   EnFOUv0YK1RG          0.126699          0.575446          0.509422   \n\n   0throw_4thcolumn  0throw_5thcolumn  0throw_6thcolumn  0throw_7thcolumn  \\\n0          0.524369          0.693364          0.770032          0.724406   \n1          0.363003          0.534558          0.345347          0.409471   \n2          0.196852          0.088148          0.023843          0.381782   \n3          0.471840          0.568460          0.633660          0.501113   \n4          0.363193          0.427544          0.449924          0.451796   \n\n   0throw_8thcolumn  0throw_9thcolumn  ...  195throw_196thcolumn  \\\n0          0.390118          0.547912  ...              0.080423   \n1          0.303328          0.402515  ...              0.198009   \n2          0.068979          0.377488  ...              0.051319   \n3          0.345461          0.467943  ...              0.046183   \n4          0.223927          0.298248  ...              0.315734   \n\n   195throw_197thcolumn  195throw_198thcolumn  195throw_199thcolumn  \\\n0             -0.054581             -0.088163             -0.028574   \n1             -0.000724              0.083122              0.033043   \n2              0.023630             -0.056819              0.117396   \n3             -0.238962              0.121868             -0.260970   \n4              0.002234              0.290791              0.344149   \n\n   196throw_197thcolumn  196throw_198thcolumn  196throw_199thcolumn  \\\n0              0.444847              0.350149             -0.012601   \n1              0.687497              0.306229              0.717485   \n2              0.576086              0.517831              0.527044   \n3              0.646818              0.594902              0.608156   \n4              0.480214              0.539824              0.447322   \n\n   197throw_198thcolumn  197throw_199thcolumn  198throw_199thcolumn  \n0              0.665750              0.560565              0.555732  \n1              0.461809              0.559632              0.350027  \n2              0.605038              0.609856              0.750987  \n3              0.595459              0.683189              0.542296  \n4              0.293088              0.148529              0.539823  \n\n[5 rows x 19901 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>participant_id</th>\n      <th>0throw_1thcolumn</th>\n      <th>0throw_2thcolumn</th>\n      <th>0throw_3thcolumn</th>\n      <th>0throw_4thcolumn</th>\n      <th>0throw_5thcolumn</th>\n      <th>0throw_6thcolumn</th>\n      <th>0throw_7thcolumn</th>\n      <th>0throw_8thcolumn</th>\n      <th>0throw_9thcolumn</th>\n      <th>...</th>\n      <th>195throw_196thcolumn</th>\n      <th>195throw_197thcolumn</th>\n      <th>195throw_198thcolumn</th>\n      <th>195throw_199thcolumn</th>\n      <th>196throw_197thcolumn</th>\n      <th>196throw_198thcolumn</th>\n      <th>196throw_199thcolumn</th>\n      <th>197throw_198thcolumn</th>\n      <th>197throw_199thcolumn</th>\n      <th>198throw_199thcolumn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cfwaf5FX7jWK</td>\n      <td>0.548480</td>\n      <td>0.713607</td>\n      <td>0.557319</td>\n      <td>0.524369</td>\n      <td>0.693364</td>\n      <td>0.770032</td>\n      <td>0.724406</td>\n      <td>0.390118</td>\n      <td>0.547912</td>\n      <td>...</td>\n      <td>0.080423</td>\n      <td>-0.054581</td>\n      <td>-0.088163</td>\n      <td>-0.028574</td>\n      <td>0.444847</td>\n      <td>0.350149</td>\n      <td>-0.012601</td>\n      <td>0.665750</td>\n      <td>0.560565</td>\n      <td>0.555732</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>vhGrzmvA3Hjq</td>\n      <td>0.427740</td>\n      <td>0.363022</td>\n      <td>0.402862</td>\n      <td>0.363003</td>\n      <td>0.534558</td>\n      <td>0.345347</td>\n      <td>0.409471</td>\n      <td>0.303328</td>\n      <td>0.402515</td>\n      <td>...</td>\n      <td>0.198009</td>\n      <td>-0.000724</td>\n      <td>0.083122</td>\n      <td>0.033043</td>\n      <td>0.687497</td>\n      <td>0.306229</td>\n      <td>0.717485</td>\n      <td>0.461809</td>\n      <td>0.559632</td>\n      <td>0.350027</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ULliyEXjy4OV</td>\n      <td>0.139572</td>\n      <td>0.390106</td>\n      <td>-0.087041</td>\n      <td>0.196852</td>\n      <td>0.088148</td>\n      <td>0.023843</td>\n      <td>0.381782</td>\n      <td>0.068979</td>\n      <td>0.377488</td>\n      <td>...</td>\n      <td>0.051319</td>\n      <td>0.023630</td>\n      <td>-0.056819</td>\n      <td>0.117396</td>\n      <td>0.576086</td>\n      <td>0.517831</td>\n      <td>0.527044</td>\n      <td>0.605038</td>\n      <td>0.609856</td>\n      <td>0.750987</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LZfeAb1xMtql</td>\n      <td>0.133561</td>\n      <td>0.778326</td>\n      <td>0.416355</td>\n      <td>0.471840</td>\n      <td>0.568460</td>\n      <td>0.633660</td>\n      <td>0.501113</td>\n      <td>0.345461</td>\n      <td>0.467943</td>\n      <td>...</td>\n      <td>0.046183</td>\n      <td>-0.238962</td>\n      <td>0.121868</td>\n      <td>-0.260970</td>\n      <td>0.646818</td>\n      <td>0.594902</td>\n      <td>0.608156</td>\n      <td>0.595459</td>\n      <td>0.683189</td>\n      <td>0.542296</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>EnFOUv0YK1RG</td>\n      <td>0.126699</td>\n      <td>0.575446</td>\n      <td>0.509422</td>\n      <td>0.363193</td>\n      <td>0.427544</td>\n      <td>0.449924</td>\n      <td>0.451796</td>\n      <td>0.223927</td>\n      <td>0.298248</td>\n      <td>...</td>\n      <td>0.315734</td>\n      <td>0.002234</td>\n      <td>0.290791</td>\n      <td>0.344149</td>\n      <td>0.480214</td>\n      <td>0.539824</td>\n      <td>0.447322</td>\n      <td>0.293088</td>\n      <td>0.148529</td>\n      <td>0.539823</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 19901 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set index for merging\n",
    "test_cat.set_index(\"participant_id\", inplace=True)\n",
    "test_quant.set_index(\"participant_id\", inplace=True)\n",
    "test_func.set_index(\"participant_id\", inplace=True)\n",
    "\n",
    "# train_cat.head()\n",
    "train_func.head()\n",
    "# train_quant.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T03:17:50.974945Z",
     "start_time": "2025-04-21T03:17:50.895278Z"
    }
   },
   "id": "7d0cce83e162f93e",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in train_quant:\n",
      " EHQ_EHQ_Total                  1\n",
      "ColorVision_CV_Score           9\n",
      "APQ_P_APQ_P_CP                15\n",
      "APQ_P_APQ_P_ID                15\n",
      "APQ_P_APQ_P_INV               15\n",
      "APQ_P_APQ_P_OPD               15\n",
      "APQ_P_APQ_P_PM                15\n",
      "APQ_P_APQ_P_PP                15\n",
      "SDQ_SDQ_Conduct_Problems      30\n",
      "SDQ_SDQ_Difficulties_Total    30\n",
      "SDQ_SDQ_Emotional_Problems    30\n",
      "SDQ_SDQ_Externalizing         30\n",
      "SDQ_SDQ_Generating_Impact     30\n",
      "SDQ_SDQ_Hyperactivity         30\n",
      "SDQ_SDQ_Internalizing         30\n",
      "SDQ_SDQ_Peer_Problems         30\n",
      "SDQ_SDQ_Prosocial             30\n",
      "dtype: int64\n",
      "Missing values in train_cat:\n",
      " PreInt_Demos_Fam_Child_Ethnicity     3\n",
      "PreInt_Demos_Fam_Child_Race          6\n",
      "Barratt_Barratt_P1_Edu               1\n",
      "Barratt_Barratt_P1_Occ               1\n",
      "Barratt_Barratt_P2_Edu              36\n",
      "Barratt_Barratt_P2_Occ              42\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Select only fMRI columns\n",
    "fmri_data = test_func.drop(columns=['participant_id'], errors='ignore')\n",
    "\n",
    "# Apply PCA to reduce to top N components (e.g. 50)\n",
    "pca = PCA(n_components=50)\n",
    "fmri_pca = pca.fit_transform(fmri_data)\n",
    "\n",
    "test_func_pca = pd.DataFrame(fmri_pca, index=test_func.index,\n",
    "                           columns=[f'fmri_pca_{i}' for i in range(1, 51)])\n",
    "test_func_pca.head()\n",
    "\n",
    "# Check missing values *before* merging\n",
    "missing = test_quant.isnull().sum()\n",
    "missing_cat = test_cat.isnull().sum()\n",
    "print(\"Missing values in train_quant:\\n\", missing[missing > 0])\n",
    "print(\"Missing values in train_cat:\\n\", missing_cat[missing_cat > 0])\n",
    "\n",
    "# Define columns with small gaps to impute\n",
    "small_gap_cols = [\n",
    "    'EHQ_EHQ_Total', 'ColorVision_CV_Score',\n",
    "    'APQ_P_APQ_P_CP', 'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV',\n",
    "    'APQ_P_APQ_P_OPD', 'APQ_P_APQ_P_PM', 'APQ_P_APQ_P_PP',\n",
    "    'SDQ_SDQ_Conduct_Problems', 'SDQ_SDQ_Difficulties_Total',\n",
    "    'SDQ_SDQ_Emotional_Problems', 'SDQ_SDQ_Externalizing',\n",
    "    'SDQ_SDQ_Generating_Impact', 'SDQ_SDQ_Hyperactivity',\n",
    "    'SDQ_SDQ_Internalizing', 'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial',\n",
    "    'PreInt_Demos_Fam_Child_Ethnicity', 'PreInt_Demos_Fam_Child_Race',\n",
    "    'MRI_Track_Scan_Location'\n",
    "]\n",
    "\n",
    "small_gap_cols_cat = [\n",
    "    'Barratt_Barratt_P1_Edu', 'Barratt_Barratt_P1_Occ'\n",
    "]\n",
    "\n",
    "# Fill small gaps using column means\n",
    "for col in small_gap_cols:\n",
    "    if col in test_quant.columns:\n",
    "        test_quant[col] = test_quant[col].fillna(test_quant[col].mean())\n",
    "for col in small_gap_cols_cat:\n",
    "    if col in test_cat.columns:\n",
    "        test_cat[col] = test_cat[col].fillna(test_cat[col].mean())\n",
    "\n",
    "test_quant.drop(columns=['MRI_Track_Age_at_Scan'], inplace=True) # Dropped\n",
    "test_cat.drop(columns=['Barratt_Barratt_P2_Occ', 'Barratt_Barratt_P2_Edu'], \n",
    "              inplace=True) # Dropped\n",
    "\n",
    "# Make sure participant_id is a column, not the index\n",
    "test_quant = test_quant.reset_index()\n",
    "test_cat = test_cat.reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T03:20:36.403525Z",
     "start_time": "2025-04-21T03:20:31.178932Z"
    }
   },
   "id": "cd0694b833f64311",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "    participant_id  ADHD_Outcome  Sex_F\n0     Cfwaf5FX7jWK             1      0\n1     vhGrzmvA3Hjq             1      1\n2     ULliyEXjy4OV             1      0\n3     LZfeAb1xMtql             1      0\n4     EnFOUv0YK1RG             1      0\n..             ...           ...    ...\n299   UadZfjdEg7eG             1      0\n300   IUEHiLmQAqCi             1      1\n301   cRySmCadYFRO             1      0\n302   E3MvDUtJadc5             1      0\n303   dQJXfyRazknD             0      0\n\n[304 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>participant_id</th>\n      <th>ADHD_Outcome</th>\n      <th>Sex_F</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cfwaf5FX7jWK</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>vhGrzmvA3Hjq</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ULliyEXjy4OV</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LZfeAb1xMtql</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>EnFOUv0YK1RG</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>UadZfjdEg7eG</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>IUEHiLmQAqCi</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>cRySmCadYFRO</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>E3MvDUtJadc5</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>303</th>\n      <td>dQJXfyRazknD</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>304 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize test data\n",
    "X_test_scaled = scaler.transform(X_test_selected)\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "\n",
    "# Load into DataLoader\n",
    "test_loader_final = DataLoader(X_test_tensor, batch_size=32)\n",
    "\n",
    "# Set model to eval mode and load best weights\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "\n",
    "adhd_preds, sex_preds = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb in test_loader_final:\n",
    "        adhd_out, sex_out = model(xb)\n",
    "        adhd_preds.append(adhd_out)\n",
    "        sex_preds.append(sex_out)\n",
    "\n",
    "# Concatenate and threshold at 0.5\n",
    "adhd_preds = torch.cat(adhd_preds).squeeze().numpy()\n",
    "sex_preds = torch.cat(sex_preds).squeeze().numpy()\n",
    "\n",
    "adhd_pred_labels = (adhd_preds > 0.5).astype(int)\n",
    "sex_pred_labels = (sex_preds > 0.5).astype(int)\n",
    "\n",
    "# Create test_soln submission DataFrame\n",
    "test_soln = pd.DataFrame({\n",
    "    'participant_id': X_full['participant_id'],  # or test_func['participant_id']\n",
    "    'ADHD_Outcome': adhd_pred_labels,\n",
    "    'Sex_F': sex_pred_labels\n",
    "})\n",
    "\n",
    "test_soln.to_csv(\"submission.csv\", index=False)\n",
    "test_soln"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T03:37:14.657735Z",
     "start_time": "2025-04-21T03:37:14.560300Z"
    }
   },
   "id": "a9da8b679a035942",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5d462c8c46aa2a6e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
